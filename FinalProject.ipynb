{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project links, files, and basic information\n",
    "\n",
    "### Websites with datasets:\n",
    "- San Diego Vehicle Stops:  https://data.sandiego.gov/datasets/police-vehicle-stops/\n",
    "- Dan Diego Population Data:  http://www.city-data.com/city/San-Diego-California.html\n",
    "\n",
    "### Websites of needed information:\n",
    "- San Diego police service areas https://www.sandiego.gov/police/services/divisions (vehcle stop data only records the first two digits)\n",
    "- San Diego zip code map: http://www.city-data.com/zipmaps/San-Diego-California.html\n",
    "\n",
    "### Names of datasets\n",
    "#### *Vehicle Stops*\n",
    "- 'vehicle_stops_2017.csv'\n",
    "- 'vehicle_stops_2016.csv'\n",
    "- 'vehicle_stops_2015.csv'\n",
    "- 'vehicle_stops_2014.csv'\n",
    "\n",
    "#### *Vehicle Stops Details*\n",
    "- 'vehicle_stops_search_details_2017.csv'\n",
    "- 'vehicle_stops_search_details_2016.csv'\n",
    "- 'vehicle_stops_search_details_2015.csv'\n",
    "- 'vehicle_stops_search_details_2014.csv'\n",
    "\n",
    "#### *Files needed to read Vehicle Stops information*\n",
    "- Race Codes: 'vehicle_stops_race_codes.csv'    \n",
    "- Title explanations for Vehicle Stops data: 'vehicle_stops_dictionary.csv'\n",
    "- Title explanations for Vehicle Stops Details data: 'vehicle_stops_search_details_dictionary.csv'\n",
    "- Possible actions taken when stopped for Vehicle Stops Details data: 'vehicle_stops_search_details_description_list.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gordee\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "\n",
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Web scrapping\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} beautifulsoup4\n",
    "\n",
    "# Data analysis\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind, chisquare, normaltest\n",
    "\n",
    "import requests\n",
    "import PyPDF2 as pdf\n",
    "#import urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stops = pd.read_csv('vehicle_stops_2017.csv')\n",
    "df_stops_info = pd.read_csv('vehicle_stops_search_details_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31659, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df_stops_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The races that make up the majority of the san diego area\n",
    "races = list(['W', 'H', 'A', 'B', 'I', 'O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulls population chart from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# function to get population data from a specific zip code ######################\n",
    "import os\n",
    "import PyPDF2 as pdf\n",
    "import locale\n",
    "\n",
    "def get_zip_info(code, percent):\n",
    "    locale.setlocale(locale.LC_ALL, '')\n",
    "    currDir = 'zip_pop_data\\\\'\n",
    "    try:\n",
    "        file = currDir + code + '.pdf'\n",
    "        fpdf = pdf.PdfFileReader(file)\n",
    "        page = fpdf.getPage(0).extractText()\n",
    "\n",
    "        # Gets the beginning and end of the data we want\n",
    "        index = page.find('Population\\nPercent\\nTotal Population')\n",
    "        indexEnd = page.find('Source: SANDAG, Current Estimates (2010)\\nPopulation by Race')\n",
    "        text = page[index+19:indexEnd-1]\n",
    "        text = list(text)\n",
    "        for index, item in enumerate(text):\n",
    "            if item == \"\\n\":\n",
    "                text[index] = '/'\n",
    "\n",
    "        text = ''.join(text)\n",
    "        text = text.split('/')\n",
    "        groups = list()\n",
    "        percentages = list()\n",
    "        populations = list()\n",
    "        cols = ['Group', 'Population', 'Percent']\n",
    "\n",
    "        for item in text:\n",
    "            if '%' in item:\n",
    "                percentages.append(item)\n",
    "            elif item[0].isnumeric():\n",
    "                populations.append(locale.atoi(item) * np.float(percent))\n",
    "            else:\n",
    "                groups.append(item) \n",
    "\n",
    "        p_df = pd.DataFrame(columns = cols)\n",
    "        p_df['Group'] = groups\n",
    "        p_df['Population'] = populations\n",
    "        p_df['Percent'] = percentages\n",
    "        p_df.set_index('Group', inplace=True)\n",
    "        p_df = p_df.reindex([\"Total Population\", \"White\", \"Hispanic\", \"Asian\", \"Black\", \"Two or More\", \"American Indian\",\n",
    "                    \"Pacific Islander\", \"Other\"])\n",
    "        p_df.fillna(0.0, inplace=True)\n",
    "        \n",
    "        # Makes sure that each value in percent column has a % sign on it - fixes errors caused by null\n",
    "        \n",
    "        for index, row in p_df.iterrows():\n",
    "            if '%' not in str(row['Percent']):\n",
    "                p_df.loc[index, 'Percent'] = str(row['Percent']) + '%'\n",
    "        return p_df\n",
    "    except PermissionError:\n",
    "        print('error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DELETE BEFORE TURNIN ###\n",
    "import os\n",
    "\n",
    "currDir = 'zip_pop_data\\\\'\n",
    "for currZip in os.listdir('zip_pop_data'):  \n",
    "    try:\n",
    "        file = os.fsdecode(currZip)\n",
    "        fpdf = pdf.PdfFileReader(currDir + file)\n",
    "        page = fpdf.getPage(0).extractText()\n",
    "\n",
    "        # Gets the beginning and end of the data we want\n",
    "        index = page.find('Population\\nPercent\\nTotal Population')\n",
    "        indexEnd = page.find('Source: SANDAG, Current Estimates (2010)\\nPopulation by Race')\n",
    "        text = page[index+19:indexEnd-1]\n",
    "        text = list(text)\n",
    "        for index, item in enumerate(text):\n",
    "            if item == \"\\n\":\n",
    "                text[index] = '/'\n",
    "\n",
    "        text = ''.join(text)\n",
    "        text = text.split('/')\n",
    "        groups = list()\n",
    "        percentages = list()\n",
    "        populations = list()\n",
    "        cols = ['Group', 'Population', 'Percent']\n",
    "\n",
    "        for item in text:\n",
    "            if '%' in item:\n",
    "                percentages.append(item)\n",
    "            elif item[0].isnumeric():\n",
    "                populations.append(item)\n",
    "            else:\n",
    "                groups.append(item) \n",
    "\n",
    "\n",
    "        p_df = pd.DataFrame(columns = cols)\n",
    "        p_df['Group'] = groups\n",
    "        p_df['Population'] = populations\n",
    "        p_df['Percent'] = percentages\n",
    "        print(file)\n",
    "        print(p_df)\n",
    "        print('\\n')\n",
    "    except PermissionError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning stops dataframe - fuctions\n",
    "    ### Clean unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wanted column titles for stops dataframe\n",
    "stops_col_titles = ['stop_id','stop_cause','service_area','subject_race','subject_sex','subject_age',\n",
    "                    'arrested','searched','contraband_found','property_seized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to get rid of unwanted columns in vehicle stop dataset - Alberto\n",
    "# Params: stops - dataset of stops to clean\n",
    "def clean_stops_cols(stops):\n",
    "    \n",
    "    #Obtain unwated columns and drop them\n",
    "    drop_list = np.setdiff1d(list(stops),stops_col_titles)\n",
    "    stops.drop(drop_list, axis=1, inplace=True)\n",
    "    \n",
    "    return stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean NaNs and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If nans exist of these columns the entry will be dropped\n",
    "clean_nans_cols = ['stop_cause', 'stop_id', 'subject_race', 'subject_sex', 'subject_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to get rid of nans vehicle stop dataset - Alberto\n",
    "# Params: stops - dataset of stops to clean\n",
    "def clean_stops_nans(stops):\n",
    "    \n",
    "    # Here we assume a Nan means a No in these columns (Since the majority of columns had 'Nan' instead of 'N')\n",
    "    stops['arrested'] = stops['arrested'].replace({np.nan:'N'})\n",
    "    stops['searched'] = stops['searched'].replace({np.nan:'N'})\n",
    "    stops['contraband_found'] = stops['contraband_found'].replace({np.nan:'N'})\n",
    "    stops['property_seized'] = stops['property_seized'].replace({np.nan:'N'})\n",
    "    \n",
    "    stops.dropna(how = 'any', subset = clean_nans_cols, inplace = True)\n",
    "    \n",
    "    return stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning stops detail dataframe - functions\n",
    "    Clean unwanted columns of stop details dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wanted column titles for stops information dataframe\n",
    "stops_info_col_titles = ['stop_id','search_details_type','search_details_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to get rid of unwanted columns in vehicle stop informationdataset - Alberto\n",
    "# Params: stops_info - dataset of stops information to clean\n",
    "def clean_stops_info_cols(stops_info):\n",
    "    \n",
    "    #Obtain unwated columns and drop them\n",
    "    drop_list = np.setdiff1d(list(stops_info),stops_info_col_titles)\n",
    "    stops_info.drop(drop_list, axis=1, inplace=True) \n",
    "    \n",
    "    return stops_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean NaNs and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Take out meaningless entry\n",
    "# Params: stops_info - dataset of stops information to clean\n",
    "def clean_stops_info_meaningless(stops_info):\n",
    "    \n",
    "    stops_info = stops_info[~((stops_info['search_details_type'] == 'ActionTakenOther') \n",
    "                                      & stops_info['search_details_description'].isnull())]\n",
    "    stops_info = stops_info[~((stops_info['search_details_type'] == 'ActionTaken') \n",
    "                                      & (stops_info['search_details_description'] == 'Other'))]\n",
    "    stops_info = stops_info[~((stops_info['search_details_type'] == 'SearchBasis') \n",
    "                                      & (stops_info['search_details_description'] == 'Other'))]\n",
    "    return stops_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarize action type entry\n",
    "# Params: action - string to be standarized\n",
    "def standardize_action_type(action_type):\n",
    "    action_type = str(action_type)\n",
    "    action_type = action_type.lower()\n",
    "    \n",
    "    if 'action' in action_type:\n",
    "        action_type = 'action'\n",
    "    \n",
    "    elif 'search' in action_type:\n",
    "        action_type = 'search'\n",
    "        \n",
    "    return action_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarize action details entry\n",
    "# Params: action - string to be standarized\n",
    "def standardize_action_desc(action):\n",
    "    \n",
    "    # Otherwise move onto parsinf\n",
    "    action = str(action)\n",
    "    action = action.lower()\n",
    "\n",
    "    if 'nan' in action:\n",
    "        #action = np.nan\n",
    "        action = 'Other'\n",
    "        \n",
    "    elif 'arrest' in action:\n",
    "        action = ['arrest']\n",
    "        \n",
    "    elif '310' in action:\n",
    "        action = ['310']\n",
    "        \n",
    "    elif 'imp' in action:\n",
    "        action = ['impound']\n",
    "\n",
    "    elif 'tow' in action:\n",
    "        action = ['tow']\n",
    "        \n",
    "    elif 'mistake' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'released' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'leave' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'free' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'no vio' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'no dui' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'nothing' in action:\n",
    "        action = ['released']\n",
    "         \n",
    "    elif 'notice' in action:\n",
    "        action = ['suspension notice']\n",
    "        \n",
    "    elif 'plate' in action:\n",
    "        action = ['check plate']\n",
    "        \n",
    "    elif 'passenger' in action:\n",
    "        action = ['passenger']\n",
    "        \n",
    "    elif 'license' in action:\n",
    "        action = ['license']\n",
    "        \n",
    "    elif 'dui' in action:\n",
    "        action = ['dui eval']\n",
    "        \n",
    "    elif 'det' in action:\n",
    "        action = ['detention']\n",
    "        \n",
    "    elif 'contact' in action:\n",
    "        action = ['contact']\n",
    "        \n",
    "    elif 'suspen' in action:\n",
    "        action = ['suspension']\n",
    "    \n",
    "    elif 'susp' in action:\n",
    "        action = ['suspect']\n",
    "        \n",
    "    elif 'cit' in action:\n",
    "        action = ['citation']\n",
    "        \n",
    "    elif 'dmv' in action:\n",
    "        action = ['DMV issue']\n",
    "        \n",
    "    else:\n",
    "        action = 'Other'\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean nans and reduce descriptions\n",
    "# Params: stops_info - dataset of stops information to clean\n",
    "def clean_stops_info_nans(stops_info):\n",
    "    \n",
    "    # Clean meaningless columns\n",
    "    stops_info = clean_stops_info_meaningless(stops_info)\n",
    "    \n",
    "    # Clean type column\n",
    "    type_title = 'search_details_type'\n",
    "    stops_info[type_title] = stops_info[type_title].apply(standardize_action_type)\n",
    "    \n",
    "    # Clean details column\n",
    "    desc_title = 'search_details_description'\n",
    "    stops_info[desc_title] = stops_info[desc_title].apply(standardize_action_desc)\n",
    "    \n",
    "    # Remove 'Other' and nan entries as they do not give us any extra information\n",
    "    stops_info = stops_info[~(stops_info['search_details_description'] == \"Other\")]\n",
    "    stops_info.dropna(how = 'any', subset = stops_info_col_titles, inplace = True)\n",
    "    \n",
    "    return stops_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine cleaning dataframe functions into one\n",
    "# Params: stops - stops dataframe to be cleaned\n",
    "def clean_stops(stops):\n",
    "    stops = clean_stops_cols(stops)\n",
    "    stops = clean_stops_nans(stops)\n",
    "    \n",
    "    return stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine cleaning dataframe functions into one\n",
    "# Params: stops_info - stops information dataframe to be cleaned\n",
    "def clean_stops_info(stops_info):\n",
    "    stops_info = clean_stops_info_cols(stops_info)\n",
    "    stops_info = clean_stops_info_nans(stops_info)\n",
    "    return stops_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in 2017 datasets\n",
    "df_stops_17 = pd.read_csv('vehicle_stops_2017.csv')\n",
    "df_stops_16 = pd.read_csv('vehicle_stops_2016.csv')\n",
    "df_stops_15 = pd.read_csv('vehicle_stops_2015.csv')\n",
    "df_stops_14 = pd.read_csv('vehicle_stops_2014.csv')\n",
    "\n",
    "df_stops_17 = clean_stops(df_stops_17)\n",
    "df_stops_16 = clean_stops(df_stops_16)\n",
    "df_stops_15 = clean_stops(df_stops_15)\n",
    "df_stops_14 = clean_stops(df_stops_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in 2017 datasets\n",
    "df_stops_info_17 = pd.read_csv('vehicle_stops_search_details_2017.csv')\n",
    "df_stops_info_16 = pd.read_csv('vehicle_stops_search_details_2016.csv')\n",
    "df_stops_info_15 = pd.read_csv('vehicle_stops_search_details_2015.csv')\n",
    "df_stops_info_14 = pd.read_csv('vehicle_stops_search_details_2014.csv')\n",
    "\n",
    "df_stops_info_17 = clean_stops_info(df_stops_info_17)\n",
    "df_stops_info_16 = clean_stops_info(df_stops_info_16)\n",
    "df_stops_info_15 = clean_stops_info(df_stops_info_15)\n",
    "df_stops_info_14 = clean_stops_info(df_stops_info_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the stops and details dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Merges duplicates within the information dataser\n",
    "# Params: info - dataframe with stops information\n",
    "def merge_duplicates(info):\n",
    "    \n",
    "    deleted = 0\n",
    "    last_index = len(info) -1\n",
    "\n",
    "    for index, row in info.iterrows():\n",
    "    \n",
    "        if deleted > 0:\n",
    "            deleted -= 1\n",
    "        \n",
    "        elif index < last_index:\n",
    "        \n",
    "            s_id = row['stop_id']\n",
    "        \n",
    "            next_index = index+1\n",
    "            next_id = info['stop_id'][next_index]\n",
    "    \n",
    "            while (s_id == next_id) & (next_index <= last_index):\n",
    "            \n",
    "                # Grab entry of duplicate\n",
    "                entry = info.loc[next_index, 'search_details_description']\n",
    "            \n",
    "                # Append duplicate entry to original\n",
    "                info.loc[index, 'search_details_description'].append(entry[0])\n",
    "            \n",
    "                # Drop duplicate row\n",
    "                info.drop(next_index, inplace=True)\n",
    "            \n",
    "                # Increase index of next row\n",
    "                next_index += 1\n",
    "            \n",
    "                # Check for out of bounds\n",
    "                if next_index  < last_index:\n",
    "                    next_id = info['stop_id'][next_index]\n",
    "                \n",
    "                deleted += 1\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Merge the stops and details dataframes\n",
    "# Params: stops - dataframe with stops information\n",
    "#          info - dataframe with stop details\n",
    "def merge_dataframes(stops, info):\n",
    "    \n",
    "    \n",
    "    # Drop type information\n",
    "    info.drop('search_details_type', axis=1, inplace=True)\n",
    "    \n",
    "    # Reset indeces\n",
    "    info = info.reset_index()\n",
    "    info.drop('index', axis=1, inplace=True)\n",
    "    \n",
    "    # Merge duplicates of information dataset\n",
    "    info = merge_duplicates(info)\n",
    "    \n",
    "    df_merged = stops.merge(info, on = ['stop_id'], how = 'left')\n",
    "    \n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = {\n",
    "    '2017': merge_dataframes(df_stops_17, df_stops_info_17),\n",
    "    '2016': merge_dataframes(df_stops_16, df_stops_info_16),\n",
    "    '2015': merge_dataframes(df_stops_15, df_stops_info_15),\n",
    "    '2014': merge_dataframes(df_stops_14, df_stops_info_14)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged = merge_dataframes(df_stops_17, df_stops_info_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_cause</th>\n",
       "      <th>service_area</th>\n",
       "      <th>subject_race</th>\n",
       "      <th>subject_sex</th>\n",
       "      <th>subject_age</th>\n",
       "      <th>arrested</th>\n",
       "      <th>searched</th>\n",
       "      <th>contraband_found</th>\n",
       "      <th>property_seized</th>\n",
       "      <th>search_details_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1444799</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>120</td>\n",
       "      <td>I</td>\n",
       "      <td>M</td>\n",
       "      <td>37</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1444821</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>520</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1447102</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>520</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1444801</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>720</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>61</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1444802</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>120</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stop_id           stop_cause service_area subject_race subject_sex  \\\n",
       "0  1444799     Moving Violation          120            I           M   \n",
       "1  1444821  Equipment Violation          520            W           M   \n",
       "2  1447102     Moving Violation          520            W           M   \n",
       "3  1444801  Equipment Violation          720            H           F   \n",
       "4  1444802  Equipment Violation          120            H           M   \n",
       "\n",
       "  subject_age arrested searched contraband_found property_seized  \\\n",
       "0          37        N        N                N               N   \n",
       "1          22        N        N                N               N   \n",
       "2          29        N        N                N               N   \n",
       "3          61        N        N                N               N   \n",
       "4          24        N        N                N               N   \n",
       "\n",
       "  search_details_description  \n",
       "0                 [citation]  \n",
       "1                        NaN  \n",
       "2                 [citation]  \n",
       "3                        NaN  \n",
       "4                        NaN  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years['2017'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps all of the police race data into appropriate categories that\n",
    "# the census gives us\n",
    "\n",
    "def assign_race(race):\n",
    "# A = asian, B = black, H = hispanic, I = indian, O = other\n",
    "    race_dict = {}\n",
    "\n",
    "    race_dict['A'] = 'A'\n",
    "    race_dict['B'] = 'B'\n",
    "    race_dict['C'] = 'A'\n",
    "    race_dict['D'] = 'A'\n",
    "    race_dict['F'] = 'A'\n",
    "    race_dict['G'] = 'O'\n",
    "    race_dict['H'] = 'H'\n",
    "    race_dict['I'] = 'I'\n",
    "    race_dict['J'] = 'A'\n",
    "    race_dict['K'] = 'A'\n",
    "    race_dict['L'] = 'O' #A?\n",
    "    race_dict['O'] = 'O'\n",
    "   # race_dict['P'] = 'P'\n",
    "    race_dict['P'] = 'O'\n",
    "    race_dict['S'] = 'O' #P?\n",
    "    race_dict['U'] = 'O' #P?\n",
    "    race_dict['V'] = 'A'\n",
    "    race_dict['W'] = 'W'\n",
    "    #race_dict['Z'] = 'T'\n",
    "    race_dict['Z'] = 'O'\n",
    "\n",
    "    race_dict['X'] = 'O'\n",
    "    \n",
    "    return race_dict[race]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all police areas\n",
    "def get_year_areas():\n",
    "    df_areas = {\n",
    "        '110': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '120': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '130': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '230': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '240': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '310': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '320': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '430': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '440': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '510': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '520': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '530': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '610': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '620': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '630': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '710': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '720': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '810': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '820': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '830': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '840': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '930': [pd.DataFrame(), pd.DataFrame()],\n",
    "        'Unknown': [pd.DataFrame(), pd.DataFrame()]\n",
    "    }\n",
    "    \n",
    "    return df_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df_areas['110'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts the number of police actions for each race in each police area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_race_data(year, currArea):\n",
    "    actions = list(['arrest', '310', 'impound', 'tow', 'released', 'suspension notice', 'check plate', 'passenger',\n",
    "                   'license', 'dui eval', 'detention', 'contact', 'suspension', 'suspect', 'citation', 'DMV issue', \n",
    "                   'other', 'NaN', 'total'])\n",
    "\n",
    "    cols = ['W', 'B', 'I', 'A', 'H', 'O']\n",
    "    for df in currArea:\n",
    "        currArea[df][0] = pd.DataFrame(columns = cols)\n",
    "        currArea[df][0]['Action'] = actions\n",
    "        currArea[df][0].fillna(0, inplace=True)\n",
    "        currArea[df][0].set_index('Action', inplace=True)\n",
    "\n",
    "    for index, row in years[year].iterrows():\n",
    "        try:\n",
    "            race = assign_race(row['subject_race'])\n",
    "        except KeyError:\n",
    "            continue\n",
    "        desc = row['search_details_description']\n",
    "        area = row['service_area']\n",
    "        if desc is not np.nan:\n",
    "            currArea[area][0].loc[desc, race] += 1\n",
    "            \n",
    "    for item in cols:\n",
    "        for df in currArea:\n",
    "            currArea[df][0].loc['total', item] = currArea[df][0][item].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Counts the total population for police area\n",
    "# Since each police area covers multiple zip codes, we must loop through all codes in each area\n",
    "def fill_area_pop_data(year, currArea):\n",
    "    for area in currArea:\n",
    "        codes = get_area_zips(area)\n",
    "        if len(codes) is not 1:\n",
    "            df_total = get_zip_info(codes[0], codes[1])\n",
    "            for index in range(2,len(codes)-1, 2):\n",
    "                df_temp = get_zip_info(codes[index], codes[index+1])\n",
    "                df_total = df_total.add(df_temp, fill_value=0)\n",
    "\n",
    "            for index, row in df_total.iterrows():\n",
    "                # Calculates the new percentages of the added zip codes\n",
    "                pop = int((row['Population'] / df_total['Population'][0] * 100))\n",
    "                if pop == 0:\n",
    "                    pop = '0'\n",
    "                else:\n",
    "                    pop = str(pop)\n",
    "                df_total.loc[index, 'Percent'] = pop\n",
    "                # Turning Populations into ints\n",
    "                df_total.loc[index, 'Population'] = int(df_total.loc[index, 'Population'])\n",
    "\n",
    "            currArea[area][1] = df_total\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total(year, currArea, df):\n",
    "    total = 0\n",
    "    for item in df[currArea][0].columns:\n",
    "        total += df[currArea][0].loc['total', item]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Loads in all the data at once. Takes roughly 6 mins to run, but will make the rest of the program much faster \n",
    "df_2017 = get_year_areas()\n",
    "df_2016 = get_year_areas()\n",
    "df_2015 = get_year_areas()\n",
    "df_2014 = get_year_areas()\n",
    "\n",
    "get_code_race_data('2017', df_2017)\n",
    "get_code_race_data('2016', df_2016)\n",
    "get_code_race_data('2015', df_2015)\n",
    "get_code_race_data('2014', df_2014)\n",
    "\n",
    "fill_area_pop_data('2017', df_2017)\n",
    "fill_area_pop_data('2016', df_2016)\n",
    "fill_area_pop_data('2015', df_2015)\n",
    "fill_area_pop_data('2014', df_2014)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Population Percent\n",
      "Group                               \n",
      "Total Population     96512.0     100\n",
      "White                61684.0      63\n",
      "Hispanic              7519.0       7\n",
      "Asian                22111.0      22\n",
      "Black                 1171.0       1\n",
      "Two or More           3528.0       3\n",
      "American Indian        120.0       0\n",
      "Pacific Islander       117.0       0\n",
      "Other                  259.0       0\n"
     ]
    }
   ],
   "source": [
    "print(df_2014['930'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92122\n"
     ]
    }
   ],
   "source": [
    "# Function that maps zip codes to police areas\n",
    "def get_area_zips(area):\n",
    "    code_dict = {'110':list(['92122', '1', '92117', '1', '92111', '0.8', '92110', '0.4' ]),\n",
    "                '120': list(['92109', '1', '92037', '1']),\n",
    "                '130': list(['0']),\n",
    "                '230': list(['92129', '1', '92128', '1', '92127', '0.3', '92025', '0.3']),\n",
    "                '240': list(['92145', '1', '92126', '1', '92131', '1']),\n",
    "                '310': list(['92123', '1', '92124', '1', '92108', '1', '92111', '0.2']),\n",
    "                '320': list(['92120', '1', '92119', '1']),\n",
    "                '430': list(['92139', '1', '92114', '1']),\n",
    "                '440': list(['92136', '1', '92102', '0.4', '92113', '0.5']),\n",
    "                '510': list(['92113', '0.5', '92102', '0.6']),\n",
    "                '520': list(['92101', '1']),\n",
    "                '530': list(['0']),\n",
    "                '610': list(['92107', '1', '92106', '1', '92140', '1', '92110', '0.6']),\n",
    "                '620': list(['92103', '1']),\n",
    "                '630': list(['0']),\n",
    "                '710': list(['92173', '1', '92154', '0.4']),\n",
    "                '720': list(['92154', '0.6']),\n",
    "                '810': list(['0']),\n",
    "                '820': list(['92115', '1', '92116', '0.6']),\n",
    "                '830': list(['92105', '0.8']),\n",
    "                '840': list(['0']),\n",
    "                '930': list(['92121', '1', '92130', '1', '92014', '1', '92091', '1', '92127', '0.7']),\n",
    "                'Unknown': list(['0'])\n",
    "                }\n",
    "    return code_dict[area]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Population Percent\n",
      "Group                               \n",
      "Total Population     96512.0     100\n",
      "White                61684.0      63\n",
      "Hispanic              7519.0       7\n",
      "Asian                22111.0      22\n",
      "Black                 1171.0       1\n",
      "Two or More           3528.0       3\n",
      "American Indian        120.0       0\n",
      "Pacific Islander       117.0       0\n",
      "Other                  259.0       0\n"
     ]
    }
   ],
   "source": [
    "df_years = {\n",
    "    '2017':df_2017,\n",
    "    '2016':df_2016,\n",
    "    '2015':df_2015,\n",
    "    '2014':df_2014\n",
    "}\n",
    "\n",
    "print(df_years['2017']['930'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Compares the number of actions taken against the given race vs. the population of that race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_compare(area, race, year):\n",
    "    df_pop = df_years[year][area][1]\n",
    "    df_actions = df_years[year][area][0]\n",
    "    total = get_total(year, area, df_years[year])\n",
    "    \n",
    "    switch = {\n",
    "        'W': np.float(df_pop.loc['White', 'Percent']) / np.float(df_actions.loc['total', race] / total),#df_pop.loc['White', 'Population'] / df_actions.loc['total', race],\n",
    "        'B': np.float(df_pop.loc['Black', 'Percent']) / np.float(df_actions.loc['total', race] / total),\n",
    "       # 'I': np.float((df_actions.loc['total', race] / total)) / np.float(df_pop.loc['American Indian', 'Percent']),\n",
    "        'A': np.float(df_pop.loc['Asian', 'Percent']) / np.float(df_actions.loc['total', race] / total),\n",
    "        'H': np.float(df_pop.loc['Hispanic', 'Percent']) / np.float(df_actions.loc['total', race] / total),\n",
    "        'O': np.float(df_pop.loc['Other', 'Percent']) / np.float(df_actions.loc['total', race] / total),\n",
    "        'I': 0\n",
    "    }\n",
    "    \n",
    "    return switch[race] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.5592841163311\n"
     ]
    }
   ],
   "source": [
    "print(np.float(df_years['2017']['110'][1].loc['White', 'Percent']) / (df_years['2017']['110'][0].loc['total', 'W'] / get_total('2017', '110', df_years['2017'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 6 artists>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2765daea978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratios = list()\n",
    "for race in races:\n",
    "    ratios.append(race_compare('110', race, '2017'))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.bar(races, ratios, width=.75)\n",
    "\n",
    "#print(df_years['2016']['930'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27657cc9d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_years = ['2014', '2015', '2016', '2017']\n",
    "area_lookup = '930'\n",
    "whites = list()\n",
    "asians = list()\n",
    "hispanics = list()\n",
    "blacks = list()\n",
    "\n",
    "for year in graph_years:\n",
    "    whites.append(race_compare(area_lookup, 'W', year))\n",
    "    asians.append(race_compare(area_lookup, 'A', year))\n",
    "    hispanics.append(race_compare(area_lookup, 'H', year))\n",
    "    blacks.append(race_compare(area_lookup, 'B', year))\n",
    "    \n",
    "    \n",
    "plt.plot(graph_years, whites, 'ro')\n",
    "plt.plot(graph_years, asians, 'yo')\n",
    "plt.plot(graph_years, hispanics, 'go')\n",
    "plt.plot(graph_years, blacks, 'bo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
