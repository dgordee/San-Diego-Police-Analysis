{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project links, files, and basic information\n",
    "\n",
    "### Websites with datasets:\n",
    "- San Diego Vehicle Stops:  https://data.sandiego.gov/datasets/police-vehicle-stops/\n",
    "- Dan Diego Population Data:  http://www.city-data.com/city/San-Diego-California.html\n",
    "\n",
    "### Websites of needed information:\n",
    "- San Diego police service areas https://www.sandiego.gov/police/services/divisions (vehcle stop data only records the first two digits)\n",
    "- San Diego zip code map: http://www.city-data.com/zipmaps/San-Diego-California.html\n",
    "\n",
    "### Names of datasets\n",
    "#### *Vehicle Stops*\n",
    "- 'vehicle_stops_2017.csv'\n",
    "- 'vehicle_stops_2016.csv'\n",
    "- 'vehicle_stops_2015.csv'\n",
    "- 'vehicle_stops_2014.csv'\n",
    "\n",
    "#### *Vehicle Stops Details*\n",
    "- 'vehicle_stops_search_details_2017.csv'\n",
    "- 'vehicle_stops_search_details_2016.csv'\n",
    "- 'vehicle_stops_search_details_2015.csv'\n",
    "- 'vehicle_stops_search_details_2014.csv'\n",
    "\n",
    "#### *Files needed to read Vehicle Stops information*\n",
    "- Race Codes: 'vehicle_stops_race_codes.csv'    \n",
    "- Title explanations for Vehicle Stops data: 'vehicle_stops_dictionary.csv'\n",
    "- Title explanations for Vehicle Stops Details data: 'vehicle_stops_search_details_dictionary.csv'\n",
    "- Possible actions taken when stopped for Vehicle Stops Details data: 'vehicle_stops_search_details_description_list.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Gordee\\Anaconda3\n",
      "\n",
      "  added / updated specs: \n",
      "    - beautifulsoup4\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.5.0                |           py35_0         1.0 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    conda: 4.4.11-py35_0 --> 4.5.0-py35_0\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "(base) C:\\Users\\Gordee\\Desktop\\Pr_008>block should really be the equivalent of \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "conda 4.5.0:            |   0% \n",
      "conda 4.5.0: 1          |   1% \n",
      "conda 4.5.0: 2          |   2% \n",
      "conda 4.5.0: 3          |   3% \n",
      "conda 4.5.0: 6          |   7% \n",
      "conda 4.5.0: 7          |   8% \n",
      "conda 4.5.0: #          |  10% \n",
      "conda 4.5.0: #1         |  11% \n",
      "conda 4.5.0: #3         |  13% \n",
      "conda 4.5.0: #5         |  16% \n",
      "conda 4.5.0: #9         |  19% \n",
      "conda 4.5.0: ##1        |  21% \n",
      "conda 4.5.0: ##3        |  24% \n",
      "conda 4.5.0: ##5        |  26% \n",
      "conda 4.5.0: ##8        |  28% \n",
      "conda 4.5.0: ###        |  30% \n",
      "conda 4.5.0: ###2       |  33% \n",
      "conda 4.5.0: ###4       |  35% \n",
      "conda 4.5.0: ###7       |  37% \n",
      "conda 4.5.0: ####       |  40% \n",
      "conda 4.5.0: ####3      |  44% \n",
      "conda 4.5.0: ####7      |  47% \n",
      "conda 4.5.0: #####      |  50% \n",
      "conda 4.5.0: #####2     |  53% \n",
      "conda 4.5.0: #####4     |  55% \n",
      "conda 4.5.0: #####7     |  57% \n",
      "conda 4.5.0: #####9     |  59% \n",
      "conda 4.5.0: ######2    |  63% \n",
      "conda 4.5.0: ######5    |  65% \n",
      "conda 4.5.0: ######7    |  67% \n",
      "conda 4.5.0: ######9    |  70% \n",
      "conda 4.5.0: #######2   |  73% \n",
      "conda 4.5.0: #######5   |  75% \n",
      "conda 4.5.0: #######7   |  77% \n",
      "conda 4.5.0: #######8   |  79% \n",
      "conda 4.5.0: #######9   |  80% \n",
      "conda 4.5.0: ########1  |  81% \n",
      "conda 4.5.0: ########1  |  82% \n",
      "conda 4.5.0: ########2  |  83% \n",
      "conda 4.5.0: ########3  |  84% \n",
      "conda 4.5.0: ########4  |  84% \n",
      "conda 4.5.0: ########5  |  85% \n",
      "conda 4.5.0: ########5  |  86% \n",
      "conda 4.5.0: ########6  |  86% \n",
      "conda 4.5.0: ########7  |  87% \n",
      "conda 4.5.0: ########7  |  88% \n",
      "conda 4.5.0: ########8  |  88% \n",
      "conda 4.5.0: ########8  |  89% \n",
      "conda 4.5.0: ########9  |  90% \n",
      "conda 4.5.0: #########  |  90% \n",
      "conda 4.5.0: #########  |  91% \n",
      "conda 4.5.0: #########1 |  91% \n",
      "conda 4.5.0: #########1 |  92% \n",
      "conda 4.5.0: #########2 |  92% \n",
      "conda 4.5.0: #########2 |  93% \n",
      "conda 4.5.0: #########3 |  94% \n",
      "conda 4.5.0: #########4 |  94% \n",
      "conda 4.5.0: #########4 |  95% \n",
      "conda 4.5.0: #########5 |  95% \n",
      "conda 4.5.0: #########5 |  96% \n",
      "conda 4.5.0: #########6 |  96% \n",
      "conda 4.5.0: #########6 |  97% \n",
      "conda 4.5.0: #########7 |  97% \n",
      "conda 4.5.0: #########7 |  98% \n",
      "conda 4.5.0: #########8 |  98% \n",
      "conda 4.5.0: #########8 |  99% \n",
      "conda 4.5.0: #########9 |  99% \n",
      "conda 4.5.0: ########## | 100% \n",
      "'block' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "C:\\Users\\Gordee\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "\n",
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Web scrapping\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} beautifulsoup4\n",
    "\n",
    "# Data analysis\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind, chisquare, normaltest\n",
    "\n",
    "import requests\n",
    "import PyPDF2 as pdf\n",
    "#import urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stops = pd.read_csv('vehicle_stops_2017.csv')\n",
    "df_stops_info = pd.read_csv('vehicle_stops_search_details_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31659, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df_stops_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total Population</th>\n",
       "      <td>24137.5</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>9191.0</td>\n",
       "      <td>38%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hispanic</th>\n",
       "      <td>12857.0</td>\n",
       "      <td>53%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>993.0</td>\n",
       "      <td>4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>467.5</td>\n",
       "      <td>2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two or More</th>\n",
       "      <td>428.5</td>\n",
       "      <td>2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Indian</th>\n",
       "      <td>107.5</td>\n",
       "      <td>&lt;1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pacific Islander</th>\n",
       "      <td>48.5</td>\n",
       "      <td>&lt;1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>44.5</td>\n",
       "      <td>&lt;1%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Population Percent\n",
       "Group                               \n",
       "Total Population     24137.5    100%\n",
       "White                 9191.0     38%\n",
       "Hispanic             12857.0     53%\n",
       "Asian                  993.0      4%\n",
       "Black                  467.5      2%\n",
       "Two or More            428.5      2%\n",
       "American Indian        107.5     <1%\n",
       "Pacific Islander        48.5     <1%\n",
       "Other                   44.5     <1%"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################# function to get population data from a specific zip code ######################\n",
    "import os\n",
    "import PyPDF2 as pdf\n",
    "import locale\n",
    "\n",
    "def get_zip_info(code, percent):\n",
    "    locale.setlocale(locale.LC_ALL, '')\n",
    "    currDir = 'zip_pop_data\\\\'\n",
    "    try:\n",
    "        file = currDir + code + '.pdf'\n",
    "        fpdf = pdf.PdfFileReader(file)\n",
    "        page = fpdf.getPage(0).extractText()\n",
    "\n",
    "        # Gets the beginning and end of the data we want\n",
    "        index = page.find('Population\\nPercent\\nTotal Population')\n",
    "        indexEnd = page.find('Source: SANDAG, Current Estimates (2010)\\nPopulation by Race')\n",
    "        text = page[index+19:indexEnd-1]\n",
    "        text = list(text)\n",
    "        for index, item in enumerate(text):\n",
    "            if item == \"\\n\":\n",
    "                text[index] = '/'\n",
    "\n",
    "        text = ''.join(text)\n",
    "        text = text.split('/')\n",
    "        groups = list()\n",
    "        percentages = list()\n",
    "        populations = list()\n",
    "        cols = ['Group', 'Population', 'Percent']\n",
    "\n",
    "        for item in text:\n",
    "            if '%' in item:\n",
    "                percentages.append(item)\n",
    "            elif item[0].isnumeric():\n",
    "                populations.append(locale.atoi(item) * np.float(percent))\n",
    "            else:\n",
    "                groups.append(item) \n",
    "\n",
    "        p_df = pd.DataFrame(columns = cols)\n",
    "        p_df['Group'] = groups\n",
    "        p_df['Population'] = populations\n",
    "        p_df['Percent'] = percentages\n",
    "        p_df.set_index('Group', inplace=True)\n",
    "        p_df = p_df.reindex([\"Total Population\", \"White\", \"Hispanic\", \"Asian\", \"Black\", \"Two or More\", \"American Indian\",\n",
    "                    \"Pacific Islander\", \"Other\"])\n",
    "        return p_df\n",
    "    except PermissionError:\n",
    "        print('error')\n",
    "        \n",
    "df = get_zip_info('92025', '.5')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92014.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     13,432    100%\n",
      "1             White     11,481     85%\n",
      "2             Asian        797      6%\n",
      "3          Hispanic        686      5%\n",
      "4       Two or More        329      2%\n",
      "5             Black         75      1%\n",
      "6             Other         46     <1%\n",
      "7   American Indian         11     <1%\n",
      "8  Pacific Islander          7     <1%\n",
      "\n",
      "\n",
      "92025.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     48,275    100%\n",
      "1          Hispanic     25,714     53%\n",
      "2             White     18,382     38%\n",
      "3             Asian      1,986      4%\n",
      "4             Black        935      2%\n",
      "5       Two or More        857      2%\n",
      "6   American Indian        215     <1%\n",
      "7  Pacific Islander         97     <1%\n",
      "8             Other         89     <1%\n",
      "\n",
      "\n",
      "92091.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population      1,621    100%\n",
      "1             White      1,408     87%\n",
      "2          Hispanic         99      6%\n",
      "3             Asian         80      5%\n",
      "4       Two or More         24      1%\n",
      "5             Black          4     <1%\n",
      "6   American Indian          4     <1%\n",
      "7             Other          2     <1%\n",
      "\n",
      "\n",
      "92101.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     35,623    100%\n",
      "1             White     20,971     59%\n",
      "2          Hispanic      7,600     21%\n",
      "3             Black      3,060      9%\n",
      "4             Asian      2,565      7%\n",
      "5       Two or More      1,058      3%\n",
      "6   American Indian        181      1%\n",
      "7             Other        102     <1%\n",
      "8  Pacific Islander         86     <1%\n",
      "\n",
      "\n",
      "92102.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     42,967    100%\n",
      "1          Hispanic     26,906     63%\n",
      "2             White      8,174     19%\n",
      "3             Black      4,237     10%\n",
      "4             Asian      2,490      6%\n",
      "5       Two or More        819      2%\n",
      "6  Pacific Islander        144     <1%\n",
      "7   American Indian        102     <1%\n",
      "8             Other         95     <1%\n",
      "\n",
      "\n",
      "92103.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     30,680    100%\n",
      "1             White     22,506     73%\n",
      "2          Hispanic      4,447     14%\n",
      "3             Asian      1,756      6%\n",
      "4       Two or More        879      3%\n",
      "5             Black        848      3%\n",
      "6   American Indian        105     <1%\n",
      "7             Other         78     <1%\n",
      "8  Pacific Islander         61     <1%\n",
      "\n",
      "\n",
      "92104.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     44,947    100%\n",
      "1             White     20,990     47%\n",
      "2          Hispanic     15,590     35%\n",
      "3             Black      3,891      9%\n",
      "4             Asian      2,525      6%\n",
      "5       Two or More      1,480      3%\n",
      "6   American Indian        188     <1%\n",
      "7  Pacific Islander        162     <1%\n",
      "8             Other        121     <1%\n",
      "\n",
      "\n",
      "92105.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     70,270    100%\n",
      "1          Hispanic     38,011     54%\n",
      "2             Asian     12,566     18%\n",
      "3             Black      9,304     13%\n",
      "4             White      8,362     12%\n",
      "5       Two or More      1,493      2%\n",
      "6  Pacific Islander        218     <1%\n",
      "7   American Indian        178     <1%\n",
      "8             Other        138     <1%\n",
      "\n",
      "\n",
      "92106.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     21,847    100%\n",
      "1             White     17,237     79%\n",
      "2          Hispanic      2,440     11%\n",
      "3             Asian        716      3%\n",
      "4       Two or More        613      3%\n",
      "5             Black        602      3%\n",
      "6             Other         89     <1%\n",
      "7   American Indian         83     <1%\n",
      "8  Pacific Islander         67     <1%\n",
      "\n",
      "\n",
      "92107.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     26,929    100%\n",
      "1             White     22,066     82%\n",
      "2          Hispanic      2,814     10%\n",
      "3       Two or More        730      3%\n",
      "4             Asian        644      2%\n",
      "5             Black        394      1%\n",
      "6             Other        127     <1%\n",
      "7   American Indian        100     <1%\n",
      "8  Pacific Islander         54     <1%\n",
      "\n",
      "\n",
      "92108.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     18,191    100%\n",
      "1             White     10,988     60%\n",
      "2          Hispanic      3,197     18%\n",
      "3             Asian      1,989     11%\n",
      "4             Black      1,067      6%\n",
      "5       Two or More        742      4%\n",
      "6  Pacific Islander         93      1%\n",
      "7   American Indian         61     <1%\n",
      "8             Other         54     <1%\n",
      "\n",
      "\n",
      "92110.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     23,852    100%\n",
      "1             White     15,903     67%\n",
      "2          Hispanic      4,308     18%\n",
      "3             Asian      1,253      5%\n",
      "4             Black      1,210      5%\n",
      "5       Two or More        899      4%\n",
      "6             Other        109     <1%\n",
      "7  Pacific Islander         93     <1%\n",
      "8   American Indian         77     <1%\n",
      "\n",
      "\n",
      "92111.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     47,870    100%\n",
      "1             White     21,691     45%\n",
      "2          Hispanic     12,899     27%\n",
      "3             Asian      8,435     18%\n",
      "4             Black      2,548      5%\n",
      "5       Two or More      1,746      4%\n",
      "6  Pacific Islander        235     <1%\n",
      "7   American Indian        178     <1%\n",
      "8             Other        138     <1%\n",
      "\n",
      "\n",
      "92113.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     51,210    100%\n",
      "1          Hispanic     40,059     78%\n",
      "2             Black      6,171     12%\n",
      "3             White      2,637      5%\n",
      "4             Asian      1,397      3%\n",
      "5       Two or More        562      1%\n",
      "6  Pacific Islander        235     <1%\n",
      "7   American Indian         94     <1%\n",
      "8             Other         55     <1%\n",
      "\n",
      "\n",
      "92114.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     65,433    100%\n",
      "1          Hispanic     26,767     41%\n",
      "2             Asian     15,287     23%\n",
      "3             Black     14,666     22%\n",
      "4             White      5,687      9%\n",
      "5       Two or More      2,050      3%\n",
      "6  Pacific Islander        729      1%\n",
      "7   American Indian        148     <1%\n",
      "8             Other         99     <1%\n",
      "\n",
      "\n",
      "92115.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     56,694    100%\n",
      "1             White     23,236     41%\n",
      "2          Hispanic     16,773     30%\n",
      "3             Asian      8,163     14%\n",
      "4             Black      6,090     11%\n",
      "5       Two or More      1,889      3%\n",
      "6  Pacific Islander        215     <1%\n",
      "7   American Indian        166     <1%\n",
      "8             Other        162     <1%\n",
      "\n",
      "\n",
      "92116.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     31,439    100%\n",
      "1             White     17,253     55%\n",
      "2          Hispanic      8,935     28%\n",
      "3             Black      2,478      8%\n",
      "4             Asian      1,460      5%\n",
      "5       Two or More        996      3%\n",
      "6   American Indian        117     <1%\n",
      "7  Pacific Islander        104     <1%\n",
      "8             Other         96     <1%\n",
      "\n",
      "\n",
      "92117.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     50,617    100%\n",
      "1             White     31,446     62%\n",
      "2          Hispanic     11,201     22%\n",
      "3             Asian      4,715      9%\n",
      "4       Two or More      1,761      3%\n",
      "5             Black      1,008      2%\n",
      "6  Pacific Islander        192     <1%\n",
      "7   American Indian        160     <1%\n",
      "8             Other        134     <1%\n",
      "\n",
      "\n",
      "92119.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     23,039    100%\n",
      "1             White     16,758     73%\n",
      "2          Hispanic      3,222     14%\n",
      "3             Asian      1,205      5%\n",
      "4             Black        829      4%\n",
      "5       Two or More        787      3%\n",
      "6  Pacific Islander        109     <1%\n",
      "7   American Indian         78     <1%\n",
      "8             Other         51     <1%\n",
      "\n",
      "\n",
      "92120.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     26,185    100%\n",
      "1             White     18,928     72%\n",
      "2          Hispanic      3,691     14%\n",
      "3             Asian      1,518      6%\n",
      "4             Black        913      3%\n",
      "5       Two or More        908      3%\n",
      "6   American Indian         93     <1%\n",
      "7  Pacific Islander         79     <1%\n",
      "8             Other         55     <1%\n",
      "\n",
      "\n",
      "92121.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population      4,253    100%\n",
      "1             White      2,172     51%\n",
      "2             Asian      1,426     34%\n",
      "3          Hispanic        411     10%\n",
      "4       Two or More        166      4%\n",
      "5             Black         60      1%\n",
      "6             Other         10     <1%\n",
      "7  Pacific Islander          4     <1%\n",
      "8   American Indian          4     <1%\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92122.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     43,382    100%\n",
      "1             White     23,612     54%\n",
      "2             Asian     13,321     31%\n",
      "3          Hispanic      4,083      9%\n",
      "4       Two or More      1,464      3%\n",
      "5             Black        635      1%\n",
      "6             Other        139     <1%\n",
      "7  Pacific Islander         72     <1%\n",
      "8   American Indian         56     <1%\n",
      "\n",
      "\n",
      "92123.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     26,343    100%\n",
      "1             White     13,560     51%\n",
      "2          Hispanic      5,170     20%\n",
      "3             Asian      3,679     14%\n",
      "4             Black      2,169      8%\n",
      "5       Two or More      1,337      5%\n",
      "6  Pacific Islander        193      1%\n",
      "7   American Indian        162      1%\n",
      "8             Other         73     <1%\n",
      "\n",
      "\n",
      "92124.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     30,332    100%\n",
      "1             White     18,498     61%\n",
      "2          Hispanic      4,844     16%\n",
      "3             Asian      3,031     10%\n",
      "4             Black      1,868      6%\n",
      "5       Two or More      1,734      6%\n",
      "6  Pacific Islander        157      1%\n",
      "7   American Indian        125     <1%\n",
      "8             Other         75     <1%\n",
      "\n",
      "\n",
      "92126.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     73,037    100%\n",
      "1             Asian     31,629     43%\n",
      "2             White     23,761     33%\n",
      "3          Hispanic     10,157     14%\n",
      "4       Two or More      3,450      5%\n",
      "5             Black      3,153      4%\n",
      "6  Pacific Islander        481      1%\n",
      "7             Other        209     <1%\n",
      "8   American Indian        197     <1%\n",
      "\n",
      "\n",
      "92127.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     39,272    100%\n",
      "1             White     22,122     56%\n",
      "2             Asian     10,502     27%\n",
      "3          Hispanic      3,717      9%\n",
      "4       Two or More      1,769      5%\n",
      "5             Black        902      2%\n",
      "6             Other        102     <1%\n",
      "7  Pacific Islander         89     <1%\n",
      "8   American Indian         69     <1%\n",
      "\n",
      "\n",
      "92128.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     47,393    100%\n",
      "1             White     30,300     64%\n",
      "2             Asian     10,071     21%\n",
      "3          Hispanic      4,007      8%\n",
      "4       Two or More      1,703      4%\n",
      "5             Black      1,047      2%\n",
      "6  Pacific Islander        101     <1%\n",
      "7   American Indian         90     <1%\n",
      "8             Other         74     <1%\n",
      "\n",
      "\n",
      "92129.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     51,208    100%\n",
      "1             White     26,566     52%\n",
      "2             Asian     15,438     30%\n",
      "3          Hispanic      5,077     10%\n",
      "4       Two or More      2,487      5%\n",
      "5             Black      1,269      2%\n",
      "6  Pacific Islander        148     <1%\n",
      "7             Other        131     <1%\n",
      "8   American Indian         92     <1%\n",
      "\n",
      "\n",
      "92130.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     49,716    100%\n",
      "1             White     31,138     63%\n",
      "2             Asian     12,457     25%\n",
      "3          Hispanic      3,722      7%\n",
      "4       Two or More      1,771      4%\n",
      "5             Black        401      1%\n",
      "6             Other        130     <1%\n",
      "7   American Indian         53     <1%\n",
      "8  Pacific Islander         44     <1%\n",
      "\n",
      "\n",
      "92131.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     34,326    100%\n",
      "1             White     21,398     62%\n",
      "2             Asian      7,634     22%\n",
      "3          Hispanic      2,925      9%\n",
      "4       Two or More      1,370      4%\n",
      "5             Black        766      2%\n",
      "6             Other         98     <1%\n",
      "7   American Indian         76     <1%\n",
      "8  Pacific Islander         59     <1%\n",
      "\n",
      "\n",
      "92139.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     35,082    100%\n",
      "1          Hispanic     13,108     37%\n",
      "2             Asian     11,003     31%\n",
      "3             White      4,610     13%\n",
      "4             Black      4,412     13%\n",
      "5       Two or More      1,402      4%\n",
      "6  Pacific Islander        417      1%\n",
      "7             Other         75     <1%\n",
      "8   American Indian         55     <1%\n",
      "\n",
      "\n",
      "92140.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population      3,435    100%\n",
      "1             White      2,400     70%\n",
      "2          Hispanic        644     19%\n",
      "3             Black        141      4%\n",
      "4       Two or More         94      3%\n",
      "5             Asian         87      3%\n",
      "6   American Indian         45      1%\n",
      "7  Pacific Islander         16     <1%\n",
      "8             Other          8     <1%\n",
      "\n",
      "\n",
      "92145.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population          2    100%\n",
      "1             White          2    100%\n",
      "\n",
      "\n",
      "92154.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     79,233    100%\n",
      "1          Hispanic     52,298     66%\n",
      "2             Asian     10,322     13%\n",
      "3             White     10,191     13%\n",
      "4             Black      3,983      5%\n",
      "5       Two or More      1,777      2%\n",
      "6  Pacific Islander        261     <1%\n",
      "7             Other        248     <1%\n",
      "8   American Indian        153     <1%\n",
      "\n",
      "\n",
      "92173.pdf\n",
      "              Group Population Percent\n",
      "0  Total Population     29,318    100%\n",
      "1          Hispanic     27,216     93%\n",
      "2             White        835      3%\n",
      "3             Asian        658      2%\n",
      "4             Black        375      1%\n",
      "5       Two or More        158      1%\n",
      "6  Pacific Islander         43     <1%\n",
      "7   American Indian         17     <1%\n",
      "8             Other         16     <1%\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "PdfReadError",
     "evalue": "EOF marker not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPdfReadError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fb28f69dd14a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfsdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrZip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mfpdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPdfFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrDir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfpdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetPage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PyPDF2\\pdf.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, stream, strict, warndest, overwriteWarnings)\u001b[0m\n\u001b[0;32m   1082\u001b[0m             \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m             \u001b[0mfileobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1084\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1085\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PyPDF2\\pdf.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m   1694\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mb_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%%EOF\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1695\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlast1K\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1696\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPdfReadError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"EOF marker not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1697\u001b[0m             \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadNextEndLine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1698\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"  line:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPdfReadError\u001b[0m: EOF marker not found"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "currDir = 'zip_pop_data\\\\'\n",
    "for currZip in os.listdir('zip_pop_data'):  \n",
    "    try:\n",
    "        file = os.fsdecode(currZip)\n",
    "        fpdf = pdf.PdfFileReader(currDir + file)\n",
    "        page = fpdf.getPage(0).extractText()\n",
    "\n",
    "        # Gets the beginning and end of the data we want\n",
    "        index = page.find('Population\\nPercent\\nTotal Population')\n",
    "        indexEnd = page.find('Source: SANDAG, Current Estimates (2010)\\nPopulation by Race')\n",
    "        text = page[index+19:indexEnd-1]\n",
    "        text = list(text)\n",
    "        for index, item in enumerate(text):\n",
    "            if item == \"\\n\":\n",
    "                text[index] = '/'\n",
    "\n",
    "        text = ''.join(text)\n",
    "        text = text.split('/')\n",
    "        groups = list()\n",
    "        percentages = list()\n",
    "        populations = list()\n",
    "        cols = ['Group', 'Population', 'Percent']\n",
    "\n",
    "        for item in text:\n",
    "            if '%' in item:\n",
    "                percentages.append(item)\n",
    "            elif item[0].isnumeric():\n",
    "                populations.append(item)\n",
    "            else:\n",
    "                groups.append(item) \n",
    "\n",
    "\n",
    "        p_df = pd.DataFrame(columns = cols)\n",
    "        p_df['Group'] = groups\n",
    "        p_df['Population'] = populations\n",
    "        p_df['Percent'] = percentages\n",
    "        print(file)\n",
    "        print(p_df)\n",
    "        print('\\n')\n",
    "    except PermissionError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wanted column titles for stops dataframe\n",
    "stops_col_titles = ['stop_id','stop_cause','service_area','subject_race','subject_sex','subject_age',\n",
    "                    'arrested','searched','contraband_found','property_seized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to get rid of unwanted columns in vehicle stop dataset - Alberto\n",
    "# Params: stops - dataset of stops to clean\n",
    "def clean_stops_cols(stops):\n",
    "    \n",
    "    #Obtain unwated columns and drop them\n",
    "    drop_list = np.setdiff1d(list(stops),stops_col_titles)\n",
    "    stops.drop(drop_list, axis=1, inplace=True)\n",
    "    \n",
    "    return stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If nans exist of these columns the entry will be dropped\n",
    "clean_nans_cols = ['stop_cause', 'stop_id', 'subject_race', 'subject_sex', 'subject_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to get rid of nans vehicle stop dataset - Alberto\n",
    "# Params: stops - dataset of stops to clean\n",
    "def clean_stops_nans(stops):\n",
    "    \n",
    "    # Here we assume a Nan means a No in these columns (Since the majority of columns had 'Nan' instead of 'N')\n",
    "    stops['arrested'] = stops['arrested'].replace({np.nan:'N'})\n",
    "    stops['searched'] = stops['searched'].replace({np.nan:'N'})\n",
    "    stops['contraband_found'] = stops['contraband_found'].replace({np.nan:'N'})\n",
    "    stops['property_seized'] = stops['property_seized'].replace({np.nan:'N'})\n",
    "    \n",
    "    stops.dropna(how = 'any', subset = clean_nans_cols, inplace = True)\n",
    "    \n",
    "    return stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wanted column titles for stops information dataframe\n",
    "stops_info_col_titles = ['stop_id','search_details_type','search_details_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to get rid of unwanted columns in vehicle stop informationdataset - Alberto\n",
    "# Params: stops_info - dataset of stops information to clean\n",
    "def clean_stops_info_cols(stops_info):\n",
    "    \n",
    "    #Obtain unwated columns and drop them\n",
    "    drop_list = np.setdiff1d(list(stops_info),stops_info_col_titles)\n",
    "    stops_info.drop(drop_list, axis=1, inplace=True) \n",
    "    \n",
    "    return stops_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Take out meaningless entry\n",
    "# Params: stops_info - dataset of stops information to clean\n",
    "def clean_stops_info_meaningless(stops_info):\n",
    "    \n",
    "    stops_info = stops_info[~((stops_info['search_details_type'] == 'ActionTakenOther') \n",
    "                                      & stops_info['search_details_description'].isnull())]\n",
    "    stops_info = stops_info[~((stops_info['search_details_type'] == 'ActionTaken') \n",
    "                                      & (stops_info['search_details_description'] == 'Other'))]\n",
    "    stops_info = stops_info[~((stops_info['search_details_type'] == 'SearchBasis') \n",
    "                                      & (stops_info['search_details_description'] == 'Other'))]\n",
    "    return stops_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarize action type entry\n",
    "# Params: action - string to be standarized\n",
    "def standardize_action_type(action_type):\n",
    "    action_type = str(action_type)\n",
    "    action_type = action_type.lower()\n",
    "    \n",
    "    if 'action' in action_type:\n",
    "        action_type = 'action'\n",
    "    \n",
    "    elif 'search' in action_type:\n",
    "        action_type = 'search'\n",
    "        \n",
    "    return action_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarize action details entry\n",
    "# Params: action - string to be standarized\n",
    "def standardize_action_desc(action):\n",
    "    \n",
    "    # Otherwise move onto parsinf\n",
    "    action = str(action)\n",
    "    action = action.lower()\n",
    "\n",
    "    if 'nan' in action:\n",
    "        #action = np.nan\n",
    "        action = 'Other'\n",
    "        \n",
    "    elif 'arrest' in action:\n",
    "        action = ['arrest']\n",
    "        \n",
    "    elif '310' in action:\n",
    "        action = ['310']\n",
    "        \n",
    "    elif 'imp' in action:\n",
    "        action = ['impound']\n",
    "\n",
    "    elif 'tow' in action:\n",
    "        action = ['tow']\n",
    "        \n",
    "    elif 'mistake' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'released' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'leave' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'free' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'no vio' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'no dui' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'nothing' in action:\n",
    "        action = ['released']\n",
    "         \n",
    "    elif 'notice' in action:\n",
    "        action = ['suspension notice']\n",
    "        \n",
    "    elif 'plate' in action:\n",
    "        action = ['check plate']\n",
    "        \n",
    "    elif 'passenger' in action:\n",
    "        action = ['passenger']\n",
    "        \n",
    "    elif 'license' in action:\n",
    "        action = ['license']\n",
    "        \n",
    "    elif 'dui' in action:\n",
    "        action = ['dui eval']\n",
    "        \n",
    "    elif 'det' in action:\n",
    "        action = ['detention']\n",
    "        \n",
    "    elif 'contact' in action:\n",
    "        action = ['contact']\n",
    "        \n",
    "    elif 'suspen' in action:\n",
    "        action = ['suspension']\n",
    "    \n",
    "    elif 'susp' in action:\n",
    "        action = ['suspect']\n",
    "        \n",
    "    elif 'cit' in action:\n",
    "        action = ['citation']\n",
    "        \n",
    "    elif 'dmv' in action:\n",
    "        action = ['DMV issue']\n",
    "        \n",
    "    else:\n",
    "        action = 'Other'\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean nans and reduce descriptions\n",
    "# Params: stops_info - dataset of stops information to clean\n",
    "def clean_stops_info_nans(stops_info):\n",
    "    \n",
    "    # Clean meaningless columns\n",
    "    stops_info = clean_stops_info_meaningless(stops_info)\n",
    "    \n",
    "    # Clean type column\n",
    "    type_title = 'search_details_type'\n",
    "    stops_info[type_title] = stops_info[type_title].apply(standardize_action_type)\n",
    "    \n",
    "    # Clean details column\n",
    "    desc_title = 'search_details_description'\n",
    "    stops_info[desc_title] = stops_info[desc_title].apply(standardize_action_desc)\n",
    "    \n",
    "    # Remove 'Other' and nan entries as they do not give us any extra information\n",
    "    stops_info = stops_info[~(stops_info['search_details_description'] == \"Other\")]\n",
    "    stops_info.dropna(how = 'any', subset = stops_info_col_titles, inplace = True)\n",
    "    \n",
    "    return stops_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine cleaning dataframe functions into one\n",
    "# Params: stops - stops dataframe to be cleaned\n",
    "def clean_stops(stops):\n",
    "    stops = clean_stops_cols(stops)\n",
    "    stops = clean_stops_nans(stops)\n",
    "    \n",
    "    return stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine cleaning dataframe functions into one\n",
    "# Params: stops_info - stops information dataframe to be cleaned\n",
    "def clean_stops_info(stops_info):\n",
    "    stops_info = clean_stops_info_cols(stops_info)\n",
    "    stops_info = clean_stops_info_nans(stops_info)\n",
    "    return stops_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in 2017 datasets\n",
    "df_stops_17 = pd.read_csv('vehicle_stops_2017.csv')\n",
    "df_stops_17 = clean_stops(df_stops_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in 2017 datasets\n",
    "df_stops_info_17 = pd.read_csv('vehicle_stops_search_details_2017.csv')\n",
    "df_stops_info_17 = clean_stops_info(df_stops_info_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Merges duplicates within the information dataser\n",
    "# Params: info - dataframe with stops information\n",
    "def merge_duplicates(info):\n",
    "    \n",
    "    deleted = 0\n",
    "    last_index = len(info) -1\n",
    "\n",
    "    for index, row in info.iterrows():\n",
    "    \n",
    "        if deleted > 0:\n",
    "            deleted -= 1\n",
    "        \n",
    "        elif index < last_index:\n",
    "        \n",
    "            s_id = row['stop_id']\n",
    "        \n",
    "            next_index = index+1\n",
    "            next_id = info['stop_id'][next_index]\n",
    "    \n",
    "            while (s_id == next_id) & (next_index <= last_index):\n",
    "            \n",
    "                # Grab entry of duplicate\n",
    "                entry = info.loc[next_index, 'search_details_description']\n",
    "            \n",
    "                # Append duplicate entry to original\n",
    "                info.loc[index, 'search_details_description'].append(entry[0])\n",
    "            \n",
    "                # Drop duplicate row\n",
    "                info.drop(next_index, inplace=True)\n",
    "            \n",
    "                # Increase index of next row\n",
    "                next_index += 1\n",
    "            \n",
    "                # Check for out of bounds\n",
    "                if next_index  < last_index:\n",
    "                    next_id = info['stop_id'][next_index]\n",
    "                \n",
    "                deleted += 1\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Merge the stops and details dataframes\n",
    "# Params: stops - dataframe with stops information\n",
    "#          info - dataframe with stop details\n",
    "def merge_dataframes(stops, info):\n",
    "    \n",
    "    # Drop type information\n",
    "    info.drop('search_details_type', axis=1, inplace=True)\n",
    "    \n",
    "    # Reset indeces\n",
    "    info = info.reset_index()\n",
    "    info.drop('index', axis=1, inplace=True)\n",
    "    \n",
    "    # Merge duplicates of information dataset\n",
    "    info = merge_duplicates(info)\n",
    "    \n",
    "    df_merged = df_stops_17.merge(df_stops_info_17, on = ['stop_id'], how = 'left')\n",
    "    \n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in 2017 datasets\n",
    "df_stops_17 = pd.read_csv('vehicle_stops_2014.csv')\n",
    "df_stops_17 = clean_stops(df_stops_17)\n",
    "\n",
    "# Read in 2017 datasets\n",
    "df_stops_info_17 = pd.read_csv('vehicle_stops_search_details_2014.csv')\n",
    "df_stops_info_17 = clean_stops_info(df_stops_info_17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = merge_dataframes(df_stops_17, df_stops_info_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_cause</th>\n",
       "      <th>service_area</th>\n",
       "      <th>subject_race</th>\n",
       "      <th>subject_sex</th>\n",
       "      <th>subject_age</th>\n",
       "      <th>arrested</th>\n",
       "      <th>searched</th>\n",
       "      <th>contraband_found</th>\n",
       "      <th>property_seized</th>\n",
       "      <th>search_details_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1044975</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>110</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1044976</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>320</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>42</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1044977</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>320</td>\n",
       "      <td>L</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1044978</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>610</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>23</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1044980</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>930</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1044979</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>820</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1044981</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>710</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1045139</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>120</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1045141</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>120</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>36</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1045140</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>120</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>27</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stop_id           stop_cause service_area subject_race subject_sex  \\\n",
       "0  1044975     Moving Violation          110            W           M   \n",
       "1  1044976     Moving Violation          320            W           M   \n",
       "2  1044977     Moving Violation          320            L           M   \n",
       "3  1044978     Moving Violation          610            W           M   \n",
       "4  1044980  Equipment Violation          930            H           M   \n",
       "5  1044979  Equipment Violation          820            H           M   \n",
       "6  1044981     Moving Violation          710            H           F   \n",
       "7  1045139     Moving Violation          120            W           M   \n",
       "8  1045141     Moving Violation          120            W           M   \n",
       "9  1045140     Moving Violation          120            H           M   \n",
       "\n",
       "  subject_age arrested searched contraband_found property_seized  \\\n",
       "0          24        N        N                N               N   \n",
       "1          42        N        N                N               N   \n",
       "2          29        N        N                N               N   \n",
       "3          23        N        N                N               N   \n",
       "4          35        N        N                N               N   \n",
       "5          30        N        N                N               N   \n",
       "6          19        N        N                N               N   \n",
       "7          32        N        N                N               N   \n",
       "8          36        N        N                N               N   \n",
       "9          27        N        N                N               N   \n",
       "\n",
       "  search_details_description  \n",
       "0                 [citation]  \n",
       "1                        NaN  \n",
       "2                        NaN  \n",
       "3                 [citation]  \n",
       "4                 [citation]  \n",
       "5                        NaN  \n",
       "6                 [citation]  \n",
       "7                        NaN  \n",
       "8                 [citation]  \n",
       "9                 [citation]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps all of the police race data into appropriate categories that\n",
    "# the census gives us\n",
    "\n",
    "def assign_race(race):\n",
    "# A = asian, B = black, H = hispanic, I = indian, O = other, P = pacific island,\n",
    "# T = two or more\n",
    "    race_dict = {}\n",
    "\n",
    "    race_dict['A'] = 'A'\n",
    "    race_dict['B'] = 'B'\n",
    "    race_dict['C'] = 'A'\n",
    "    race_dict['D'] = 'A'\n",
    "    race_dict['F'] = 'A'\n",
    "    race_dict['G'] = 'O'\n",
    "    race_dict['H'] = 'H'\n",
    "    race_dict['I'] = 'I'\n",
    "    race_dict['J'] = 'A'\n",
    "    race_dict['K'] = 'A'\n",
    "    race_dict['L'] = 'O' #A?\n",
    "    race_dict['O'] = 'O'\n",
    "   # race_dict['P'] = 'P'\n",
    "    race_dict['P'] = 'O'\n",
    "    race_dict['S'] = 'O' #P?\n",
    "    race_dict['U'] = 'O' #P?\n",
    "    race_dict['V'] = 'A'\n",
    "    race_dict['W'] = 'W'\n",
    "    #race_dict['Z'] = 'T'\n",
    "    race_dict['Z'] = 'O'\n",
    "\n",
    "    race_dict['X'] = 'O'\n",
    "    \n",
    "    return race_dict[race]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'race_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-24b92f0b78c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_merged\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'subject_race'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mnum_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrace_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mnums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'race_dict' is not defined"
     ]
    }
   ],
   "source": [
    "num_dict = {}\n",
    "\n",
    "num_dict['A'] = 0\n",
    "num_dict['B'] = 0\n",
    "num_dict['H'] = 0\n",
    "num_dict['I'] = 0\n",
    "num_dict['O'] = 0\n",
    "num_dict['P'] = 0\n",
    "num_dict['T'] = 0\n",
    "num_dict['W'] = 0\n",
    "\n",
    "num_dict['X'] = 0\n",
    "\n",
    "for item in df_merged['subject_race']:\n",
    "    num_dict[race_dict[item]] += 1\n",
    "\n",
    "nums = num_dict.values()\n",
    "races = num_dict.keys()\n",
    "print(races)\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.bar(races, stops, width=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_zip_info() missing 1 required positional argument: 'percent'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-ba4e3e6b35a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzips\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_zip_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_zip_info() missing 1 required positional argument: 'percent'"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "zips = ['92107', '92106', '92110', '92140', '92103', '92122', '92117', \n",
    "       '92110', '92111', '92113', '92102', '92101', '92102', '92113',\n",
    "       '92139', '92114', '92105', '92154',  '92104', '92116', '92115', '92105',\n",
    "       '92154', '92173', '92104', '92116', '92115', '92116', '92105', '92123', \n",
    "       '92111', '92124', '92108', '92120', '92119', '92145', '92126', '92131',\n",
    "       '92129', '92128', '92127', '92025', '92121', '92130', '92014',\n",
    "       '92091', '92127']\n",
    "\n",
    "# Removes duplicates\n",
    "zips = list(set(zips))\n",
    "\n",
    "total_dict = {}\n",
    "\n",
    "total_dict['A'] = 0\n",
    "total_dict['B'] = 0\n",
    "total_dict['H'] = 0\n",
    "total_dict['I'] = 0\n",
    "#total_dict['O'] = 0\n",
    "#total_dict['P'] = 0\n",
    "#total_dict['T'] = 0\n",
    "total_dict['W'] = 0\n",
    "\n",
    "#total_dict['X'] = 0\n",
    "total_dict['Z'] = 0\n",
    "\n",
    "locale.setlocale(locale.LC_ALL, '')\n",
    "\n",
    "for code in zips:\n",
    "    db = get_zip_info(code)\n",
    "    \n",
    "    for index, row in db.iterrows():\n",
    "        group = row['Group']\n",
    "        pop = locale.atoi(row['Population'])\n",
    "        \n",
    "        if group == 'Hispanic':\n",
    "            total_dict['H'] += int(pop)\n",
    "        elif group == 'White':\n",
    "            total_dict['W'] += int(pop)\n",
    "        elif group == 'Black':\n",
    "            total_dict['B'] += int(pop)\n",
    "        elif group == 'Asian':\n",
    "            total_dict['A'] += int(pop)\n",
    "        elif group == 'American Indian':\n",
    "                total_dict['I'] += int(pop)\n",
    "        else:\n",
    "            total_dict['Z'] += int(pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['W', 'H', 'Z', 'A', 'B', 'I'])\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-817c36e636e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mratios\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mratios\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mratios\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'B'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'B'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mratios\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "print(total_dict.keys())\n",
    "ratios = list()\n",
    "\n",
    "ratios.append(total_dict['A'] / num_dict['A'])\n",
    "ratios.append(total_dict['B'] / num_dict['B'])\n",
    "ratios.append(total_dict['W'] / num_dict['W'])\n",
    "ratios.append(total_dict['I'] / num_dict['I'])\n",
    "ratios.append(total_dict['H'] / num_dict['H'])\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.bar(list(['A', 'B', 'W', 'I', 'H']), ratios, width=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "      <th>B</th>\n",
       "      <th>I</th>\n",
       "      <th>A</th>\n",
       "      <th>H</th>\n",
       "      <th>O</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>arrest</th>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>impound</th>\n",
       "      <td>83</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>91</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tow</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>released</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suspension notice</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check plate</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>passenger</th>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>license</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dui eval</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detention</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suspension</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suspect</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>citation</th>\n",
       "      <td>2834</td>\n",
       "      <td>213</td>\n",
       "      <td>24</td>\n",
       "      <td>321</td>\n",
       "      <td>875</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMV issue</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>2943</td>\n",
       "      <td>240</td>\n",
       "      <td>24</td>\n",
       "      <td>334</td>\n",
       "      <td>954</td>\n",
       "      <td>443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      W    B   I    A    H    O\n",
       "Action                                         \n",
       "arrest               50   12   0    3   24    5\n",
       "310                   0    0   0    0    0    2\n",
       "impound              83   12   0    8   91    8\n",
       "tow                   3    0   0    0    2    0\n",
       "released              0    1   0    0    1    0\n",
       "suspension notice     1    0   0    0    0    0\n",
       "check plate           0    0   0    0    0    0\n",
       "passenger            22    9   0    7    6    0\n",
       "license               0    0   0    0    0    0\n",
       "dui eval              1    3   0    1    1    0\n",
       "detention             1    1   0    0    0    0\n",
       "contact               0    0   0    0    0    0\n",
       "suspension            0    0   0    0    1    0\n",
       "suspect               0    0   0    1    2    0\n",
       "citation           2834  213  24  321  875  433\n",
       "DMV issue             0    0   0    0    0    0\n",
       "other                 0    0   0    0    0    0\n",
       "NaN                   0    0   0    0    0    0\n",
       "total              2943  240  24  334  954  443"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_code_race_data(code):\n",
    "    actions = list(['arrest', '310', 'impound', 'tow', 'released', 'suspension notice', 'check plate', 'passenger',\n",
    "                   'license', 'dui eval', 'detention', 'contact', 'suspension', 'suspect', 'citation', 'DMV issue', \n",
    "                   'other', 'NaN', 'total'])\n",
    "\n",
    "    df_action = pd.DataFrame(columns = ['Action', 'W', 'B', 'I', 'A', 'H', 'O'])\n",
    "    df_action['Action'] = actions\n",
    "    df_action.fillna(0, inplace=True)\n",
    "    df_action.set_index('Action', inplace=True)\n",
    "\n",
    "    for index, row in df_merged.iterrows():\n",
    "\n",
    "        race = assign_race(row['subject_race'])\n",
    "        desc = row['search_details_description']\n",
    "        area = row['service_area']\n",
    "        if desc is not np.nan and area == code:\n",
    "            df_action.loc[desc, race] += 1\n",
    "            df_action.loc['total', race] += 1\n",
    "    return df_action\n",
    "\n",
    "df_test = get_code_race_data('110')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Population Percent\n",
      "Group                               \n",
      "Total Population    141835.0    100%\n",
      "White                78772.0     55%\n",
      "Hispanic             27326.0     19%\n",
      "Asian                25285.0     17%\n",
      "Black                 4165.0      2%\n",
      "Two or More           4981.0      3%\n",
      "American Indian        389.0     <1%\n",
      "Pacific Islander       489.0     <1%\n",
      "Other                  427.0     <1%\n"
     ]
    }
   ],
   "source": [
    "def get_area_pop_data(codes):\n",
    "    df_total = get_zip_info(codes[0], codes[1])\n",
    "    for index in range(2,len(codes)-1, 2):\n",
    "        df_temp = get_zip_info(codes[index], codes[index+1])\n",
    "        df_total = df_total.add(df_temp, fill_value=0)\n",
    "    \n",
    "    for index, row in df_total.iterrows():\n",
    "        # Calculates the new percentages of the added zip codes\n",
    "        pop = int((row['Population'] / df_total['Population'][0] * 100))\n",
    "        if pop == 0:\n",
    "            pop = '<1%'\n",
    "        else:\n",
    "            pop = str(pop) + '%'\n",
    "        df_total.loc[index, 'Percent'] = pop\n",
    "        # Turning Populations into ints\n",
    "        df_total.loc[index, 'Population'] = int(df_total.loc[index, 'Population'])\n",
    "    return df_total\n",
    "\n",
    "print(get_area_pop_data(get_area_zips('110')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92122\n"
     ]
    }
   ],
   "source": [
    "def get_area_zips(area):\n",
    "    code_dict = {'110':list(['92122', '1', '92117', '1', '92111', '0.8', '92110', '0.4' ]),\n",
    "                '120': list(['92109', '1', '92037', '1']),\n",
    "                '230': list(['92129', '1', '92128', '1', '92127', '0.3', '92025', '0.3']),\n",
    "                '240': list(['92145', '1', '92126', '1', '92131', '1', '92137', '1']),\n",
    "                '310': list(['92123', '1', '92124', '1', '92108', '1', '92111', '0.2']),\n",
    "                '320': list(['92120', '1', '92119', '1']),\n",
    "                '430': list(['92139', '1', '92114', '1']),\n",
    "                '440': list(['92136', '1', '92102', '0.4', '92113', '0.5']),\n",
    "                '510': list(['92113', '0.5', '92102', '0.6']),\n",
    "                '520': list(['92101', '1']),\n",
    "                '610': list(['92107', '1', '92106', '1', '92140', '1', '92152', '1', '92110', '0.6']),\n",
    "                '620': list(['92103', '1']),\n",
    "                '710': list(['92173', '1', '92154', '0.4']),\n",
    "                '720': list(['92154', '0.6']),\n",
    "                '820': list(['92115', '1', '92116', '0.6']),\n",
    "                '830': list(['92105', '0.8']),\n",
    "                '930': list(['92121', '1', '92130', '1', '92014', '1', '92091', '1', '92127', '0.7'])\n",
    "                }\n",
    "    return code_dict[area]\n",
    "\n",
    "print(get_area_zips('110')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
