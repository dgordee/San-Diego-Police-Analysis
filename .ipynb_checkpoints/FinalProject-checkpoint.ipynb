{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project links, files, and basic information\n",
    "\n",
    "### Websites with datasets:\n",
    "- San Diego Vehicle Stops:  https://data.sandiego.gov/datasets/police-vehicle-stops/\n",
    "- Dan Diego Population Data:  http://www.city-data.com/city/San-Diego-California.html\n",
    "\n",
    "### Websites of needed information:\n",
    "- San Diego police service areas https://www.sandiego.gov/police/services/divisions (vehcle stop data only records the first two digits)\n",
    "- San Diego zip code map: http://www.city-data.com/zipmaps/San-Diego-California.html\n",
    "\n",
    "### Names of datasets\n",
    "#### *Vehicle Stops*\n",
    "- 'vehicle_stops_2017.csv'\n",
    "- 'vehicle_stops_2016.csv'\n",
    "- 'vehicle_stops_2015.csv'\n",
    "- 'vehicle_stops_2014.csv'\n",
    "\n",
    "#### *Vehicle Stops Details*\n",
    "- 'vehicle_stops_search_details_2017.csv'\n",
    "- 'vehicle_stops_search_details_2016.csv'\n",
    "- 'vehicle_stops_search_details_2015.csv'\n",
    "- 'vehicle_stops_search_details_2014.csv'\n",
    "\n",
    "#### *Files needed to read Vehicle Stops information*\n",
    "- Race Codes: 'vehicle_stops_race_codes.csv'    \n",
    "- Title explanations for Vehicle Stops data: 'vehicle_stops_dictionary.csv'\n",
    "- Title explanations for Vehicle Stops Details data: 'vehicle_stops_search_details_dictionary.csv'\n",
    "- Possible actions taken when stopped for Vehicle Stops Details data: 'vehicle_stops_search_details_description_list.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gordee\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "\n",
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Web scrapping\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} beautifulsoup4\n",
    "\n",
    "# Data analysis\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind, chisquare, normaltest\n",
    "\n",
    "import requests\n",
    "import PyPDF2 as pdf\n",
    "#import urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stops = pd.read_csv('vehicle_stops_2017.csv')\n",
    "df_stops_info = pd.read_csv('vehicle_stops_search_details_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31659, 6)\n"
     ]
    }
   ],
   "source": [
    "print(df_stops_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The races that make up the majority of the san diego area\n",
    "races = list(['W', 'H', 'A', 'B', 'O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulls population chart from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# function to get population data from a specific zip code ######################\n",
    "import os\n",
    "import PyPDF2 as pdf\n",
    "import locale\n",
    "\n",
    "def get_zip_info(code, percent):\n",
    "    locale.setlocale(locale.LC_ALL, '')\n",
    "    currDir = 'zip_pop_data\\\\'\n",
    "    try:\n",
    "        file = currDir + code + '.pdf'\n",
    "        fpdf = pdf.PdfFileReader(file)\n",
    "        page = fpdf.getPage(0).extractText()\n",
    "\n",
    "        # Gets the beginning and end of the data we want\n",
    "        index = page.find('Population\\nPercent\\nTotal Population')\n",
    "        indexEnd = page.find('Source: SANDAG, Current Estimates (2010)\\nPopulation by Race')\n",
    "        text = page[index+19:indexEnd-1]\n",
    "        text = list(text)\n",
    "        for index, item in enumerate(text):\n",
    "            if item == \"\\n\":\n",
    "                text[index] = '/'\n",
    "\n",
    "        text = ''.join(text)\n",
    "        text = text.split('/')\n",
    "        groups = list()\n",
    "        percentages = list()\n",
    "        populations = list()\n",
    "        cols = ['Group', 'Population', 'Percent']\n",
    "\n",
    "        for item in text:\n",
    "            if '%' in item:\n",
    "                percentages.append(item)\n",
    "            elif item[0].isnumeric():\n",
    "                populations.append(locale.atoi(item) * np.float(percent))\n",
    "            else:\n",
    "                groups.append(item) \n",
    "\n",
    "        p_df = pd.DataFrame(columns = cols)\n",
    "        p_df['Group'] = groups\n",
    "        p_df['Population'] = populations\n",
    "        p_df['Percent'] = percentages\n",
    "        p_df.set_index('Group', inplace=True)\n",
    "        p_df = p_df.reindex([\"Total Population\", \"White\", \"Hispanic\", \"Asian\", \"Black\", \"Two or More\", \"American Indian\",\n",
    "                    \"Pacific Islander\", \"Other\"])\n",
    "        p_df.fillna(0.0, inplace=True)\n",
    "        \n",
    "        # Makes sure that each value in percent column has a % sign on it - fixes errors caused by null\n",
    "        \n",
    "        for index, row in p_df.iterrows():\n",
    "            if '%' not in str(row['Percent']):\n",
    "                p_df.loc[index, 'Percent'] = str(row['Percent']) + '%'\n",
    "        return p_df\n",
    "    except PermissionError:\n",
    "        print('error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DELETE BEFORE TURNIN ###\n",
    "import os\n",
    "\n",
    "currDir = 'zip_pop_data\\\\'\n",
    "for currZip in os.listdir('zip_pop_data'):  \n",
    "    try:\n",
    "        file = os.fsdecode(currZip)\n",
    "        fpdf = pdf.PdfFileReader(currDir + file)\n",
    "        page = fpdf.getPage(0).extractText()\n",
    "\n",
    "        # Gets the beginning and end of the data we want\n",
    "        index = page.find('Population\\nPercent\\nTotal Population')\n",
    "        indexEnd = page.find('Source: SANDAG, Current Estimates (2010)\\nPopulation by Race')\n",
    "        text = page[index+19:indexEnd-1]\n",
    "        text = list(text)\n",
    "        for index, item in enumerate(text):\n",
    "            if item == \"\\n\":\n",
    "                text[index] = '/'\n",
    "\n",
    "        text = ''.join(text)\n",
    "        text = text.split('/')\n",
    "        groups = list()\n",
    "        percentages = list()\n",
    "        populations = list()\n",
    "        cols = ['Group', 'Population', 'Percent']\n",
    "\n",
    "        for item in text:\n",
    "            if '%' in item:\n",
    "                percentages.append(item)\n",
    "            elif item[0].isnumeric():\n",
    "                populations.append(item)\n",
    "            else:\n",
    "                groups.append(item) \n",
    "\n",
    "\n",
    "        p_df = pd.DataFrame(columns = cols)\n",
    "        p_df['Group'] = groups\n",
    "        p_df['Population'] = populations\n",
    "        p_df['Percent'] = percentages\n",
    "        print(file)\n",
    "        print(p_df)\n",
    "        print('\\n')\n",
    "    except PermissionError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning stops dataframe - fuctions\n",
    "    ### Clean unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wanted column titles for stops dataframe\n",
    "stops_col_titles = ['stop_id','stop_cause','service_area','subject_race','subject_sex','subject_age',\n",
    "                    'arrested','searched','contraband_found','property_seized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to get rid of unwanted columns in vehicle stop dataset - Alberto\n",
    "# Params: stops - dataset of stops to clean\n",
    "def clean_stops_cols(stops):\n",
    "    \n",
    "    #Obtain unwated columns and drop them\n",
    "    drop_list = np.setdiff1d(list(stops),stops_col_titles)\n",
    "    stops.drop(drop_list, axis=1, inplace=True)\n",
    "    \n",
    "    return stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean NaNs and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If nans exist of these columns the entry will be dropped\n",
    "clean_nans_cols = ['stop_cause', 'stop_id', 'subject_race', 'subject_sex', 'subject_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to get rid of nans vehicle stop dataset - Alberto\n",
    "# Params: stops - dataset of stops to clean\n",
    "def clean_stops_nans(stops):\n",
    "    \n",
    "    # Here we assume a Nan means a No in these columns (Since the majority of columns had 'Nan' instead of 'N')\n",
    "    stops['arrested'] = stops['arrested'].replace({np.nan:'N'})\n",
    "    stops['searched'] = stops['searched'].replace({np.nan:'N'})\n",
    "    stops['contraband_found'] = stops['contraband_found'].replace({np.nan:'N'})\n",
    "    stops['property_seized'] = stops['property_seized'].replace({np.nan:'N'})\n",
    "    \n",
    "    stops.dropna(how = 'any', subset = clean_nans_cols, inplace = True)\n",
    "    \n",
    "    return stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning stops detail dataframe - functions\n",
    "    Clean unwanted columns of stop details dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wanted column titles for stops information dataframe\n",
    "stops_info_col_titles = ['stop_id','search_details_type','search_details_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to get rid of unwanted columns in vehicle stop informationdataset - Alberto\n",
    "# Params: stops_info - dataset of stops information to clean\n",
    "def clean_stops_info_cols(stops_info):\n",
    "    \n",
    "    #Obtain unwated columns and drop them\n",
    "    drop_list = np.setdiff1d(list(stops_info),stops_info_col_titles)\n",
    "    stops_info.drop(drop_list, axis=1, inplace=True) \n",
    "    \n",
    "    return stops_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean NaNs and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Take out meaningless entry\n",
    "# Params: stops_info - dataset of stops information to clean\n",
    "def clean_stops_info_meaningless(stops_info):\n",
    "    \n",
    "    stops_info = stops_info[~((stops_info['search_details_type'] == 'ActionTakenOther') \n",
    "                                      & stops_info['search_details_description'].isnull())]\n",
    "    stops_info = stops_info[~((stops_info['search_details_type'] == 'ActionTaken') \n",
    "                                      & (stops_info['search_details_description'] == 'Other'))]\n",
    "    stops_info = stops_info[~((stops_info['search_details_type'] == 'SearchBasis') \n",
    "                                      & (stops_info['search_details_description'] == 'Other'))]\n",
    "    return stops_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarize action type entry\n",
    "# Params: action - string to be standarized\n",
    "def standardize_action_type(action_type):\n",
    "    action_type = str(action_type)\n",
    "    action_type = action_type.lower()\n",
    "    \n",
    "    if 'action' in action_type:\n",
    "        action_type = 'action'\n",
    "    \n",
    "    elif 'search' in action_type:\n",
    "        action_type = 'search'\n",
    "        \n",
    "    return action_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarize action details entry\n",
    "# Params: action - string to be standarized\n",
    "def standardize_action_desc(action):\n",
    "    \n",
    "    # Otherwise move onto parsinf\n",
    "    action = str(action)\n",
    "    action = action.lower()\n",
    "\n",
    "    if 'nan' in action:\n",
    "        #action = np.nan\n",
    "        action = 'Other'\n",
    "        \n",
    "    elif 'arrest' in action:\n",
    "        action = ['arrest']\n",
    "        \n",
    "    elif '310' in action:\n",
    "        action = ['310']\n",
    "        \n",
    "    elif 'imp' in action:\n",
    "        action = ['impound']\n",
    "\n",
    "    elif 'tow' in action:\n",
    "        action = ['tow']\n",
    "        \n",
    "    elif 'mistake' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'released' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'leave' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'free' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'no vio' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'no dui' in action:\n",
    "        action = ['released']\n",
    "        \n",
    "    elif 'nothing' in action:\n",
    "        action = ['released']\n",
    "         \n",
    "    elif 'notice' in action:\n",
    "        action = ['suspension notice']\n",
    "        \n",
    "    elif 'plate' in action:\n",
    "        action = ['check plate']\n",
    "        \n",
    "    elif 'passenger' in action:\n",
    "        action = ['passenger']\n",
    "        \n",
    "    elif 'license' in action:\n",
    "        action = ['license']\n",
    "        \n",
    "    elif 'dui' in action:\n",
    "        action = ['dui eval']\n",
    "        \n",
    "    elif 'det' in action:\n",
    "        action = ['detention']\n",
    "        \n",
    "    elif 'contact' in action:\n",
    "        action = ['contact']\n",
    "        \n",
    "    elif 'suspen' in action:\n",
    "        action = ['suspension']\n",
    "    \n",
    "    elif 'susp' in action:\n",
    "        action = ['suspect']\n",
    "        \n",
    "    elif 'cit' in action:\n",
    "        action = ['citation']\n",
    "        \n",
    "    elif 'dmv' in action:\n",
    "        action = ['DMV issue']\n",
    "        \n",
    "    else:\n",
    "        action = 'Other'\n",
    "        \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean nans and reduce descriptions\n",
    "# Params: stops_info - dataset of stops information to clean\n",
    "def clean_stops_info_nans(stops_info):\n",
    "    \n",
    "    # Clean meaningless columns\n",
    "    stops_info = clean_stops_info_meaningless(stops_info)\n",
    "    \n",
    "    # Clean type column\n",
    "    type_title = 'search_details_type'\n",
    "    stops_info[type_title] = stops_info[type_title].apply(standardize_action_type)\n",
    "    \n",
    "    # Clean details column\n",
    "    desc_title = 'search_details_description'\n",
    "    stops_info[desc_title] = stops_info[desc_title].apply(standardize_action_desc)\n",
    "    \n",
    "    # Remove 'Other' and nan entries as they do not give us any extra information\n",
    "    stops_info = stops_info[~(stops_info['search_details_description'] == \"Other\")]\n",
    "    stops_info.dropna(how = 'any', subset = stops_info_col_titles, inplace = True)\n",
    "    \n",
    "    return stops_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine cleaning dataframe functions into one\n",
    "# Params: stops - stops dataframe to be cleaned\n",
    "def clean_stops(stops):\n",
    "    stops = clean_stops_cols(stops)\n",
    "    stops = clean_stops_nans(stops)\n",
    "    \n",
    "    return stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine cleaning dataframe functions into one\n",
    "# Params: stops_info - stops information dataframe to be cleaned\n",
    "def clean_stops_info(stops_info):\n",
    "    stops_info = clean_stops_info_cols(stops_info)\n",
    "    stops_info = clean_stops_info_nans(stops_info)\n",
    "    return stops_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in 2017 datasets\n",
    "df_stops_17 = pd.read_csv('vehicle_stops_2017.csv')\n",
    "df_stops_16 = pd.read_csv('vehicle_stops_2016.csv')\n",
    "df_stops_15 = pd.read_csv('vehicle_stops_2015.csv')\n",
    "df_stops_14 = pd.read_csv('vehicle_stops_2014.csv')\n",
    "\n",
    "df_stops_17 = clean_stops(df_stops_17)\n",
    "df_stops_16 = clean_stops(df_stops_16)\n",
    "df_stops_15 = clean_stops(df_stops_15)\n",
    "df_stops_14 = clean_stops(df_stops_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in 2017 datasets\n",
    "df_stops_info_17 = pd.read_csv('vehicle_stops_search_details_2017.csv')\n",
    "df_stops_info_16 = pd.read_csv('vehicle_stops_search_details_2016.csv')\n",
    "df_stops_info_15 = pd.read_csv('vehicle_stops_search_details_2015.csv')\n",
    "df_stops_info_14 = pd.read_csv('vehicle_stops_search_details_2014.csv')\n",
    "\n",
    "df_stops_info_17 = clean_stops_info(df_stops_info_17)\n",
    "df_stops_info_16 = clean_stops_info(df_stops_info_16)\n",
    "df_stops_info_15 = clean_stops_info(df_stops_info_15)\n",
    "df_stops_info_14 = clean_stops_info(df_stops_info_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the stops and details dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Merges duplicates within the information dataser\n",
    "# Params: info - dataframe with stops information\n",
    "def merge_duplicates(info):\n",
    "    \n",
    "    deleted = 0\n",
    "    last_index = len(info) -1\n",
    "\n",
    "    for index, row in info.iterrows():\n",
    "    \n",
    "        if deleted > 0:\n",
    "            deleted -= 1\n",
    "        \n",
    "        elif index < last_index:\n",
    "        \n",
    "            s_id = row['stop_id']\n",
    "        \n",
    "            next_index = index+1\n",
    "            next_id = info['stop_id'][next_index]\n",
    "    \n",
    "            while (s_id == next_id) & (next_index <= last_index):\n",
    "            \n",
    "                # Grab entry of duplicate\n",
    "                entry = info.loc[next_index, 'search_details_description']\n",
    "            \n",
    "                # Append duplicate entry to original\n",
    "                info.loc[index, 'search_details_description'].append(entry[0])\n",
    "            \n",
    "                # Drop duplicate row\n",
    "                info.drop(next_index, inplace=True)\n",
    "            \n",
    "                # Increase index of next row\n",
    "                next_index += 1\n",
    "            \n",
    "                # Check for out of bounds\n",
    "                if next_index  < last_index:\n",
    "                    next_id = info['stop_id'][next_index]\n",
    "                \n",
    "                deleted += 1\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Merge the stops and details dataframes\n",
    "# Params: stops - dataframe with stops information\n",
    "#          info - dataframe with stop details\n",
    "def merge_dataframes(stops, info):\n",
    "    \n",
    "    \n",
    "    # Drop type information\n",
    "    info.drop('search_details_type', axis=1, inplace=True)\n",
    "    \n",
    "    # Reset indeces\n",
    "    info = info.reset_index()\n",
    "    info.drop('index', axis=1, inplace=True)\n",
    "    \n",
    "    # Merge duplicates of information dataset\n",
    "    info = merge_duplicates(info)\n",
    "    \n",
    "    df_merged = stops.merge(info, on = ['stop_id'], how = 'left')\n",
    "    \n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = {\n",
    "    '2017': merge_dataframes(df_stops_17, df_stops_info_17),\n",
    "    '2016': merge_dataframes(df_stops_16, df_stops_info_16),\n",
    "    '2015': merge_dataframes(df_stops_15, df_stops_info_15),\n",
    "    '2014': merge_dataframes(df_stops_14, df_stops_info_14)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged = merge_dataframes(df_stops_17, df_stops_info_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_cause</th>\n",
       "      <th>service_area</th>\n",
       "      <th>subject_race</th>\n",
       "      <th>subject_sex</th>\n",
       "      <th>subject_age</th>\n",
       "      <th>arrested</th>\n",
       "      <th>searched</th>\n",
       "      <th>contraband_found</th>\n",
       "      <th>property_seized</th>\n",
       "      <th>search_details_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1444799</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>120</td>\n",
       "      <td>I</td>\n",
       "      <td>M</td>\n",
       "      <td>37</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1444821</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>520</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1447102</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>520</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1444801</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>720</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>61</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1444802</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>120</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1444912</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>440</td>\n",
       "      <td>B</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1444804</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>520</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1444805</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>520</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>38</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[310]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1444807</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>510</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>30</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1444811</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>310</td>\n",
       "      <td>B</td>\n",
       "      <td>M</td>\n",
       "      <td>54</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1444806</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>930</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>68</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1444808</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>930</td>\n",
       "      <td>A</td>\n",
       "      <td>M</td>\n",
       "      <td>17</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1444809</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>510</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>64</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation, impound]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1444810</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>510</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1444812</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>110</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>40</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1444889</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>110</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>31</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1444814</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>310</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>29</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1444815</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>310</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1444813</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>930</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1444829</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>620</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>58</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1444817</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>110</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>21</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1444816</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>230</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>37</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1444819</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>510</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation, impound]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1444820</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>510</td>\n",
       "      <td>B</td>\n",
       "      <td>M</td>\n",
       "      <td>20</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1444823</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>240</td>\n",
       "      <td>V</td>\n",
       "      <td>M</td>\n",
       "      <td>54</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1444835</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>520</td>\n",
       "      <td>B</td>\n",
       "      <td>M</td>\n",
       "      <td>52</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation, passenger]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1444827</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>28</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[citation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1444824</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>310</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>35</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1444825</td>\n",
       "      <td>Suspect Info (I.S.</td>\n",
       "      <td>Bulletin</td>\n",
       "      <td>Log)</td>\n",
       "      <td>520</td>\n",
       "      <td>O</td>\n",
       "      <td>14:15</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>[contact]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1444837</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>710</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>37</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stop_id           stop_cause service_area subject_race subject_sex  \\\n",
       "0   1444799     Moving Violation          120            I           M   \n",
       "1   1444821  Equipment Violation          520            W           M   \n",
       "2   1447102     Moving Violation          520            W           M   \n",
       "3   1444801  Equipment Violation          720            H           F   \n",
       "4   1444802  Equipment Violation          120            H           M   \n",
       "5   1444912  Equipment Violation          440            B           M   \n",
       "6   1444804     Moving Violation          520            H           M   \n",
       "7   1444805  Equipment Violation          520            H           M   \n",
       "8   1444807  Equipment Violation          510            H           M   \n",
       "9   1444811  Equipment Violation          310            B           M   \n",
       "10  1444806     Moving Violation          930            W           M   \n",
       "11  1444808     Moving Violation          930            A           M   \n",
       "12  1444809  Equipment Violation          510            W           M   \n",
       "13  1444810     Moving Violation          510            H           M   \n",
       "14  1444812     Moving Violation          110            W           M   \n",
       "15  1444889  Equipment Violation          110            W           M   \n",
       "16  1444814     Moving Violation          310            A           F   \n",
       "17  1444815     Moving Violation          310            H           M   \n",
       "18  1444813  Equipment Violation          930            W           M   \n",
       "19  1444829     Moving Violation          620            W           M   \n",
       "20  1444817     Moving Violation          110            W           M   \n",
       "21  1444816     Moving Violation          230            O           M   \n",
       "22  1444819  Equipment Violation          510            H           F   \n",
       "23  1444820  Equipment Violation          510            B           M   \n",
       "24  1444823     Moving Violation          240            V           M   \n",
       "25  1444835  Equipment Violation          520            B           M   \n",
       "26  1444827     Moving Violation      Unknown            H           F   \n",
       "27  1444824  Equipment Violation          310            W           M   \n",
       "28  1444825   Suspect Info (I.S.     Bulletin         Log)         520   \n",
       "29  1444837     Moving Violation          710            W           M   \n",
       "\n",
       "   subject_age arrested searched contraband_found property_seized  \\\n",
       "0           37        N        N                N               N   \n",
       "1           22        N        N                N               N   \n",
       "2           29        N        N                N               N   \n",
       "3           61        N        N                N               N   \n",
       "4           24        N        N                N               N   \n",
       "5           45        N        N                N               N   \n",
       "6           45        N        N                N               N   \n",
       "7           38        N        N                N               N   \n",
       "8           30        N        N                N               N   \n",
       "9           54        N        Y                N               N   \n",
       "10          68        N        N                N               N   \n",
       "11          17        N        N                N               N   \n",
       "12          64        N        Y                N               N   \n",
       "13          25        N        N                N               N   \n",
       "14          40        N        N                N               N   \n",
       "15          31        N        N                N               N   \n",
       "16          29        N        N                N               N   \n",
       "17          24        N        N                N               N   \n",
       "18          29        N        N                N               N   \n",
       "19          58        Y        Y                N               N   \n",
       "20          21        N        N                N               N   \n",
       "21          37        N        N                N               N   \n",
       "22          39        N        Y                N               N   \n",
       "23          20        N        N                N               N   \n",
       "24          54        N        N                N               N   \n",
       "25          52        Y        Y                Y               N   \n",
       "26          28        N        N                N               N   \n",
       "27          35        N        N                N               N   \n",
       "28           O    14:15        Y                N               N   \n",
       "29          37        N        N                N               N   \n",
       "\n",
       "   search_details_description  \n",
       "0                  [citation]  \n",
       "1                         NaN  \n",
       "2                  [citation]  \n",
       "3                         NaN  \n",
       "4                         NaN  \n",
       "5                         NaN  \n",
       "6                         NaN  \n",
       "7                       [310]  \n",
       "8                         NaN  \n",
       "9                  [citation]  \n",
       "10                        NaN  \n",
       "11                        NaN  \n",
       "12        [citation, impound]  \n",
       "13                        NaN  \n",
       "14                        NaN  \n",
       "15                        NaN  \n",
       "16                 [citation]  \n",
       "17                 [citation]  \n",
       "18                        NaN  \n",
       "19                 [citation]  \n",
       "20                 [citation]  \n",
       "21                 [citation]  \n",
       "22        [citation, impound]  \n",
       "23                        NaN  \n",
       "24                 [citation]  \n",
       "25      [citation, passenger]  \n",
       "26                 [citation]  \n",
       "27                        NaN  \n",
       "28                  [contact]  \n",
       "29                        NaN  "
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years['2017'].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maps all of the police race data into appropriate categories that\n",
    "# the census gives us\n",
    "\n",
    "def assign_race(race):\n",
    "# A = asian, B = black, H = hispanic, I = indian, O = other\n",
    "    race_dict = {}\n",
    "\n",
    "    race_dict['A'] = 'A'\n",
    "    race_dict['B'] = 'B'\n",
    "    race_dict['C'] = 'A'\n",
    "    race_dict['D'] = 'A'\n",
    "    race_dict['F'] = 'A'\n",
    "    race_dict['G'] = 'O'\n",
    "    race_dict['H'] = 'H'\n",
    "    #race_dict['I'] = 'I'\n",
    "    race_dict['I'] = 'O'\n",
    "    race_dict['J'] = 'A'\n",
    "    race_dict['K'] = 'A'\n",
    "    race_dict['L'] = 'O' #A?\n",
    "    race_dict['O'] = 'O'\n",
    "   # race_dict['P'] = 'P'\n",
    "    race_dict['P'] = 'O'\n",
    "    race_dict['S'] = 'O' #P?\n",
    "    race_dict['U'] = 'O' #P?\n",
    "    race_dict['V'] = 'A'\n",
    "    race_dict['W'] = 'W'\n",
    "    #race_dict['Z'] = 'T'\n",
    "    race_dict['Z'] = 'O'\n",
    "\n",
    "    race_dict['X'] = 'O'\n",
    "    \n",
    "    return race_dict[race]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all police areas\n",
    "def get_year_areas():\n",
    "    df_areas = {\n",
    "        '110': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '120': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '130': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '230': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '240': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '310': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '320': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '430': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '440': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '510': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '520': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '530': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '610': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '620': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '630': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '710': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '720': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '810': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '820': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '830': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '840': [pd.DataFrame(), pd.DataFrame()],\n",
    "        '930': [pd.DataFrame(), pd.DataFrame()],\n",
    "        'Unknown': [pd.DataFrame(), pd.DataFrame()]\n",
    "    }\n",
    "    \n",
    "    return df_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df_areas['110'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counts the number of police actions for each race in each police area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_race_data(year, currArea):\n",
    "    actions = list(['arrest', '310', 'impound', 'tow', 'released', 'suspension notice', 'check plate', 'passenger',\n",
    "                   'license', 'dui eval', 'detention', 'contact', 'suspension', 'suspect', 'citation', 'DMV issue', \n",
    "                   'other', 'NaN', 'total'])\n",
    "\n",
    "    cols = ['W', 'B', 'A', 'H', 'O']\n",
    "    for df in currArea:\n",
    "        currArea[df][0] = pd.DataFrame(columns = cols)\n",
    "        currArea[df][0]['Action'] = actions\n",
    "        currArea[df][0].fillna(0, inplace=True)\n",
    "        currArea[df][0].set_index('Action', inplace=True)\n",
    "\n",
    "    for index, row in years[year].iterrows():\n",
    "        try:\n",
    "            race = assign_race(row['subject_race'])\n",
    "        except KeyError:\n",
    "            print(row['subject_race'])\n",
    "            continue\n",
    "        desc = row['search_details_description']\n",
    "        area = row['service_area']\n",
    "        if desc is not np.nan:\n",
    "            for item in desc:\n",
    "                currArea[area][0].loc[item, race] += 1\n",
    "            \n",
    "    for item in cols:\n",
    "        for df in currArea:\n",
    "            currArea[df][0].loc['total', item] = currArea[df][0][item].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Counts the total population for police area\n",
    "# Since each police area covers multiple zip codes, we must loop through all codes in each area\n",
    "def fill_area_pop_data(year, currArea):\n",
    "    for area in currArea:\n",
    "        codes = get_area_zips(area)\n",
    "        if len(codes) is not 1:\n",
    "            df_total = get_zip_info(codes[0], codes[1])\n",
    "            for index in range(2,len(codes)-1, 2):\n",
    "                df_temp = get_zip_info(codes[index], codes[index+1])\n",
    "                df_total = df_total.add(df_temp, fill_value=0)\n",
    "\n",
    "            for index, row in df_total.iterrows():\n",
    "                # Calculates the new percentages of the added zip codes\n",
    "                pop = np.float((np.float(row['Population']) / np.float(df_total['Population'][0] * 100)))\n",
    "                df_total.loc[index, 'Percent'] = np.float(pop) * 1000\n",
    "                # Turning Populations into ints\n",
    "                df_total.loc[index, 'Population'] = int(df_total.loc[index, 'Population'])\n",
    "\n",
    "            currArea[area][1] = df_total\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total(year, currArea, df):\n",
    "    total = 0\n",
    "    for item in df[currArea][0].columns:\n",
    "        total += df[currArea][0].loc['total', item]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Loads in all the data at once. Takes roughly 6 mins to run, but will make the rest of the program much faster \n",
    "df_2017 = get_year_areas()\n",
    "df_2016 = get_year_areas()\n",
    "df_2015 = get_year_areas()\n",
    "df_2014 = get_year_areas()\n",
    "\n",
    "get_code_race_data('2017', df_2017)\n",
    "get_code_race_data('2016', df_2016)\n",
    "get_code_race_data('2015', df_2015)\n",
    "get_code_race_data('2014', df_2014)\n",
    "\n",
    "fill_area_pop_data('2017', df_2017)\n",
    "fill_area_pop_data('2016', df_2016)\n",
    "fill_area_pop_data('2015', df_2015)\n",
    "fill_area_pop_data('2014', df_2014)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Log)\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n",
      " Log)\n",
      " Log)\n",
      " H&S Code\n",
      " Log)\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " Log)\n",
      " Log)\n",
      " Log)\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " Log)\n",
      " Log)\n",
      " Log)\n",
      " Log)\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n",
      " Log)\n",
      " Log)\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " Log)\n",
      " Log)\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " Log)\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " H&S Code\n",
      " Log)\n",
      " H&S Code\n",
      " H&S Code\n"
     ]
    }
   ],
   "source": [
    "df_2017 = get_year_areas()\n",
    "get_code_race_data('2017', df_2017)\n",
    "fill_area_pop_data('2017', df_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     W   B   A    H    O\n",
      "Action                                  \n",
      "arrest               3   1   0    2    0\n",
      "310                  1   0   0    0    0\n",
      "impound              7   0   0    2    0\n",
      "tow                  1   0   0    0    0\n",
      "released             0   0   0    0    0\n",
      "suspension notice    1   0   0    0    1\n",
      "check plate          0   0   0    0    0\n",
      "passenger            3   0   0    0    0\n",
      "license              0   0   0    0    0\n",
      "dui eval             1   0   0    0    0\n",
      "detention            0   0   0    1    0\n",
      "contact              0   1   0    0    0\n",
      "suspension           0   0   0    0    0\n",
      "suspect              0   0   0    0    0\n",
      "citation           458  33  86  122  115\n",
      "DMV issue            0   0   0    0    0\n",
      "other                0   0   0    0    0\n",
      "NaN                  0   0   0    0    0\n",
      "total              475  35  86  127  116\n"
     ]
    }
   ],
   "source": [
    "print(df_2017['930'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('vehicle_stops_search_details_2017.csv')\n",
    "df1 = pd.read_csv('vehicle_stops_2017.csv')\n",
    "df3 = df2.merge(df1,on='stop_id')\n",
    "df4 = df3[df3['service_area']=='930']\n",
    "df4 = df4[df4['subject_race']=='W']\n",
    "len(df4[df4['search_details_description']=='Citation'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>search_details_id</th>\n",
       "      <th>search_details_type</th>\n",
       "      <th>search_details_description</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>stop_cause</th>\n",
       "      <th>service_area</th>\n",
       "      <th>subject_race</th>\n",
       "      <th>subject_sex</th>\n",
       "      <th>...</th>\n",
       "      <th>stop_date</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>sd_resident</th>\n",
       "      <th>arrested</th>\n",
       "      <th>searched</th>\n",
       "      <th>obtained_consent</th>\n",
       "      <th>contraband_found</th>\n",
       "      <th>property_seized</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1444799</td>\n",
       "      <td>1628067.0</td>\n",
       "      <td>ActionTaken</td>\n",
       "      <td>Citation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>120</td>\n",
       "      <td>I</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>1/1/17</td>\n",
       "      <td>0:03</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1444821</td>\n",
       "      <td>1628097.0</td>\n",
       "      <td>ActionTaken</td>\n",
       "      <td>Verbal Warning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>520</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>1/1/17</td>\n",
       "      <td>0:25</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1447102</td>\n",
       "      <td>1630482.0</td>\n",
       "      <td>ActionTaken</td>\n",
       "      <td>Citation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>520</td>\n",
       "      <td>W</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>1/1/17</td>\n",
       "      <td>1:45</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1444801</td>\n",
       "      <td>1628069.0</td>\n",
       "      <td>ActionTaken</td>\n",
       "      <td>Verbal Warning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>720</td>\n",
       "      <td>H</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>1/1/17</td>\n",
       "      <td>3:10</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1444802</td>\n",
       "      <td>1628070.0</td>\n",
       "      <td>ActionTaken</td>\n",
       "      <td>Verbal Warning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>120</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>1/1/17</td>\n",
       "      <td>3:30</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1444912</td>\n",
       "      <td>1628192.0</td>\n",
       "      <td>ActionTaken</td>\n",
       "      <td>Verbal Warning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>440</td>\n",
       "      <td>B</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>1/1/17</td>\n",
       "      <td>3:45</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1444804</td>\n",
       "      <td>1628072.0</td>\n",
       "      <td>ActionTaken</td>\n",
       "      <td>Verbal Warning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moving Violation</td>\n",
       "      <td>520</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>1/1/17</td>\n",
       "      <td>6:55</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1444805</td>\n",
       "      <td>1628073.0</td>\n",
       "      <td>ActionTaken</td>\n",
       "      <td>Other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>520</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>1/1/17</td>\n",
       "      <td>7:25</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1444805</td>\n",
       "      <td>1628074.0</td>\n",
       "      <td>ActionTakenOther</td>\n",
       "      <td>DL 310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>520</td>\n",
       "      <td>H</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>1/1/17</td>\n",
       "      <td>7:25</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1444811</td>\n",
       "      <td>1628083.0</td>\n",
       "      <td>ActionTaken</td>\n",
       "      <td>Citation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>310</td>\n",
       "      <td>B</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>1/1/17</td>\n",
       "      <td>8:00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1444811</td>\n",
       "      <td>1628084.0</td>\n",
       "      <td>SearchType</td>\n",
       "      <td>Vehicle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>310</td>\n",
       "      <td>B</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>1/1/17</td>\n",
       "      <td>8:00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1444811</td>\n",
       "      <td>1628085.0</td>\n",
       "      <td>SearchType</td>\n",
       "      <td>Driver</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Equipment Violation</td>\n",
       "      <td>310</td>\n",
       "      <td>B</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>1/1/17</td>\n",
       "      <td>8:00</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stop_id  search_details_id search_details_type search_details_description  \\\n",
       "0   1444799          1628067.0         ActionTaken                   Citation   \n",
       "1   1444821          1628097.0         ActionTaken             Verbal Warning   \n",
       "2   1447102          1630482.0         ActionTaken                   Citation   \n",
       "3   1444801          1628069.0         ActionTaken             Verbal Warning   \n",
       "4   1444802          1628070.0         ActionTaken             Verbal Warning   \n",
       "5   1444912          1628192.0         ActionTaken             Verbal Warning   \n",
       "6   1444804          1628072.0         ActionTaken             Verbal Warning   \n",
       "7   1444805          1628073.0         ActionTaken                      Other   \n",
       "8   1444805          1628074.0    ActionTakenOther                     DL 310   \n",
       "9   1444811          1628083.0         ActionTaken                   Citation   \n",
       "10  1444811          1628084.0          SearchType                    Vehicle   \n",
       "11  1444811          1628085.0          SearchType                     Driver   \n",
       "\n",
       "   Unnamed: 4 Unnamed: 5           stop_cause service_area subject_race  \\\n",
       "0         NaN        NaN     Moving Violation          120            I   \n",
       "1         NaN        NaN  Equipment Violation          520            W   \n",
       "2         NaN        NaN     Moving Violation          520            W   \n",
       "3         NaN        NaN  Equipment Violation          720            H   \n",
       "4         NaN        NaN  Equipment Violation          120            H   \n",
       "5         NaN        NaN  Equipment Violation          440            B   \n",
       "6         NaN        NaN     Moving Violation          520            H   \n",
       "7         NaN        NaN  Equipment Violation          520            H   \n",
       "8         NaN        NaN  Equipment Violation          520            H   \n",
       "9         NaN        NaN  Equipment Violation          310            B   \n",
       "10        NaN        NaN  Equipment Violation          310            B   \n",
       "11        NaN        NaN  Equipment Violation          310            B   \n",
       "\n",
       "   subject_sex     ...     stop_date stop_time sd_resident arrested searched  \\\n",
       "0            M     ...        1/1/17      0:03           N        N        N   \n",
       "1            M     ...        1/1/17      0:25           N        N        N   \n",
       "2            M     ...        1/1/17      1:45           N        N        N   \n",
       "3            F     ...        1/1/17      3:10           N        N        N   \n",
       "4            M     ...        1/1/17      3:30           Y        N        N   \n",
       "5            M     ...        1/1/17      3:45           Y        N        N   \n",
       "6            M     ...        1/1/17      6:55           Y        N        N   \n",
       "7            M     ...        1/1/17      7:25           N        N        N   \n",
       "8            M     ...        1/1/17      7:25           N        N        N   \n",
       "9            M     ...        1/1/17      8:00           Y        N        Y   \n",
       "10           M     ...        1/1/17      8:00           Y        N        Y   \n",
       "11           M     ...        1/1/17      8:00           Y        N        Y   \n",
       "\n",
       "   obtained_consent contraband_found property_seized Unnamed: 15 Unnamed: 16  \n",
       "0               NaN              NaN             NaN         NaN         NaN  \n",
       "1               NaN              NaN             NaN         NaN         NaN  \n",
       "2               NaN              NaN             NaN         NaN         NaN  \n",
       "3               NaN              NaN             NaN         NaN         NaN  \n",
       "4               NaN              NaN             NaN         NaN         NaN  \n",
       "5               NaN              NaN             NaN         NaN         NaN  \n",
       "6               NaN              NaN             NaN         NaN         NaN  \n",
       "7               NaN              NaN             NaN         NaN         NaN  \n",
       "8               NaN              NaN             NaN         NaN         NaN  \n",
       "9                 N                N               N         NaN         NaN  \n",
       "10                N                N               N         NaN         NaN  \n",
       "11                N                N               N         NaN         NaN  \n",
       "\n",
       "[12 rows x 22 columns]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Function that maps zip codes to police areas\n",
    "def get_area_zips(area):\n",
    "    code_dict = {'110':list(['92122', '1', '92117', '1', '92111', '0.8', '92110', '0.4' ]),\n",
    "                '120': list(['92109', '1', '92037', '1']),\n",
    "                '130': list(['0']),\n",
    "                '230': list(['92129', '1', '92128', '1', '92127', '0.3', '92025', '0.3']),\n",
    "                '240': list(['92145', '1', '92126', '1', '92131', '1']),\n",
    "                '310': list(['92123', '1', '92124', '1', '92108', '1', '92111', '0.2']),\n",
    "                '320': list(['92120', '1', '92119', '1']),\n",
    "                '430': list(['92139', '1', '92114', '1']),\n",
    "                '440': list(['92136', '1', '92102', '0.4', '92113', '0.5']),\n",
    "                '510': list(['92113', '0.5', '92102', '0.6']),\n",
    "                '520': list(['92101', '1']),\n",
    "                '530': list(['0']),\n",
    "                '610': list(['92107', '1', '92106', '1', '92140', '1', '92110', '0.6']),\n",
    "                '620': list(['92103', '1']),\n",
    "                '630': list(['0']),\n",
    "                '710': list(['92173', '1', '92154', '0.4']),\n",
    "                '720': list(['92154', '0.6']),\n",
    "                '810': list(['0']),\n",
    "                '820': list(['92115', '1', '92116', '0.6']),\n",
    "                '830': list(['92105', '0.8']),\n",
    "                '840': list(['0']),\n",
    "                '930': list(['92121', '1', '92130', '1', '92014', '1', '92091', '1', '92127', '0.7']),\n",
    "                'Unknown': list(['0'])\n",
    "                }\n",
    "    return code_dict[area]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Population Percent\n",
      "Group                               \n",
      "Total Population     96512.0     100\n",
      "White                61684.0      63\n",
      "Hispanic              7519.0       7\n",
      "Asian                22111.0      22\n",
      "Black                 1171.0       1\n",
      "Two or More           3528.0       3\n",
      "American Indian        120.0       0\n",
      "Pacific Islander       117.0       0\n",
      "Other                  259.0       0\n"
     ]
    }
   ],
   "source": [
    "df_years = {\n",
    "    '2017':df_2017,\n",
    "    '2016':df_2016,\n",
    "    '2015':df_2015,\n",
    "    '2014':df_2014\n",
    "}\n",
    "\n",
    "print(df_years['2017']['930'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Compares the number of actions taken against the given race vs. the population of that race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def race_compare(area, race, year):\n",
    "    df_pop = df_years[year][area][1]\n",
    "    df_actions = df_years[year][area][0]\n",
    "    total = get_total(year, area, df_years[year])\n",
    "    other = np.float(df_pop.loc['Other', 'Population'] + df_pop.loc['Pacific Islander', 'Population'] + \n",
    "                    df_pop.loc['American Indian', 'Population'] + df_pop.loc['Two or More', 'Population'] /\n",
    "                    df_pop.loc['Total Population', 'Population'])\n",
    "    \n",
    "    switch = {\n",
    "        'W': np.float(df_actions.loc['total', race] / total / np.float(df_pop.loc['White', 'Percent'])),#df_pop.loc['White', 'Population'] / df_actions.loc['total', race],\n",
    "        'B': np.float(df_actions.loc['total', race] / total / np.float(df_pop.loc['Black', 'Percent'])),\n",
    "       # 'I': np.float((df_actions.loc['total', race] / total)) / np.float(df_pop.loc['American Indian', 'Percent']),\n",
    "        'A': np.float(df_actions.loc['total', race] / total) / np.float(df_pop.loc['Asian', 'Percent']),\n",
    "        'H': np.float(df_actions.loc['total', race] / total) / np.float(df_pop.loc['Hispanic', 'Percent']),\n",
    "        'O': np.float(df_actions.loc['total', race] / total) / np.float(df_pop.loc['Other', 'Percent']),\n",
    "        'I': 0\n",
    "    }\n",
    "    \n",
    "    return switch[race] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225.44144144144144\n"
     ]
    }
   ],
   "source": [
    "print(np.float(df_years['2017']['110'][1].loc['Asian', 'Percent']) / (df_years['2017']['110'][0].loc['total', 'A'] / get_total('2017', '110', df_years['2017'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "0.050271739130434784\n",
      "\n",
      "\n",
      "74\n",
      "1472\n",
      "0.4117647058823529\n",
      "                  Population Percent\n",
      "Group                               \n",
      "Total Population    141835.0     100\n",
      "White                78772.0      55\n",
      "Hispanic             27326.0      19\n",
      "Asian                25285.0      17\n",
      "Black                 4165.0       2\n",
      "Two or More           4981.0       3\n",
      "American Indian        389.0       0\n",
      "Pacific Islander       489.0       0\n",
      "Other                  427.0       0\n"
     ]
    }
   ],
   "source": [
    "print(np.float(df_years['2017']['110'][1].loc['Black', 'Percent']))\n",
    "print(df_years['2017']['110'][0].loc['total', 'B'] / get_total('2017', '110', df_years['2017'])) \n",
    "print('\\n')\n",
    "\n",
    "print(df_years['2017']['110'][0].loc['total', 'B'])\n",
    "print(get_total('2017', '110', df_years['2017']))\n",
    "print(7/17)\n",
    "print(df_years['2017']['110'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-355-19753918a0ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mratios\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mratios\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrace_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'110'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'2017'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-350-46959911229d>\u001b[0m in \u001b[0;36mrace_compare\u001b[1;34m(area, race, year)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;34m'A'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_actions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'total'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrace\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Asian'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Percent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;34m'H'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_actions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'total'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrace\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Hispanic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Percent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_actions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'total'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrace\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Other'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Percent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;34m'I'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     }\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "ratios = list()\n",
    "for race in races:\n",
    "    ratios.append(race_compare('110', race, '2017'))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.bar(races, ratios, width=.75)\n",
    "\n",
    "#print(df_years['2016']['930'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27657bbf6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_years = ['2014', '2015', '2016', '2017']\n",
    "area_lookup = '110'\n",
    "whites = list()\n",
    "asians = list()\n",
    "hispanics = list()\n",
    "blacks = list()\n",
    "\n",
    "for year in graph_years:\n",
    "    whites.append(race_compare(area_lookup, 'W', year))\n",
    "    asians.append(race_compare(area_lookup, 'A', year))\n",
    "    hispanics.append(race_compare(area_lookup, 'H', year))\n",
    "    blacks.append(race_compare(area_lookup, 'B', year))\n",
    "    \n",
    "    \n",
    "plt.plot(graph_years, whites, 'ro')\n",
    "plt.plot(graph_years, asians, 'yo')\n",
    "plt.plot(graph_years, hispanics, 'go')\n",
    "plt.plot(graph_years, blacks, 'bo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
